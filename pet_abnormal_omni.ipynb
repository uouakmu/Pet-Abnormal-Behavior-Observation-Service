{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db64bf87",
   "metadata": {},
   "source": [
    "## Train\n",
    "---\n",
    "- ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    - 4_Animal_Skin\n",
    "    - 5_Animal_Eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504903a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_980872/3382109964.py:437: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Epoch 1/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 01/50:   0%|                                                         | 0/1563 [00:00<?, ?it/s]/tmp/ipykernel_980872/3382109964.py:471: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "  [Skin ] Epoch 01/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:03<00:00, 12.70it/s, acc=52.56%, loss=1.4637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 01/50:   0%|                                                         | 0/2871 [00:00<?, ?it/s]/tmp/ipykernel_980872/3382109964.py:513: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "  [Eyes ] Epoch 01/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:51<00:00, 16.75it/s, acc=42.62%, loss=1.7076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 1.4637 | Acc: 52.56%\n",
      "  Eyes | Loss: 1.7076 | Acc: 42.62%\n",
      "  Avg Acc: 47.59%\n",
      "  üíæ Saved best model! (Epoch 1 | Avg Acc: 47.59%)\n",
      "\n",
      "========= Epoch 2/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 02/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:52<00:00, 13.88it/s, acc=65.55%, loss=1.2182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 02/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:52<00:00, 16.68it/s, acc=51.40%, loss=1.5058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 1.2182 | Acc: 65.55%\n",
      "  Eyes | Loss: 1.5058 | Acc: 51.40%\n",
      "  Avg Acc: 58.47%\n",
      "  üíæ Saved best model! (Epoch 2 | Avg Acc: 58.47%)\n",
      "\n",
      "========= Epoch 3/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 03/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:54<00:00, 13.65it/s, acc=71.46%, loss=1.1006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 03/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:52<00:00, 16.67it/s, acc=55.28%, loss=1.4174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 1.1006 | Acc: 71.46%\n",
      "  Eyes | Loss: 1.4174 | Acc: 55.28%\n",
      "  Avg Acc: 63.37%\n",
      "  üíæ Saved best model! (Epoch 3 | Avg Acc: 63.37%)\n",
      "\n",
      "========= Epoch 4/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 04/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:57<00:00, 13.30it/s, acc=76.03%, loss=1.0149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 04/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:51<00:00, 16.69it/s, acc=57.82%, loss=1.3508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 1.0149 | Acc: 76.03%\n",
      "  Eyes | Loss: 1.3508 | Acc: 57.82%\n",
      "  Avg Acc: 66.93%\n",
      "  üíæ Saved best model! (Epoch 4 | Avg Acc: 66.93%)\n",
      "\n",
      "========= Epoch 5/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 05/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:55<00:00, 13.54it/s, acc=79.21%, loss=0.9541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 05/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:53<00:00, 16.59it/s, acc=59.77%, loss=1.3009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.9541 | Acc: 79.21%\n",
      "  Eyes | Loss: 1.3009 | Acc: 59.77%\n",
      "  Avg Acc: 69.49%\n",
      "  üíæ Saved best model! (Epoch 5 | Avg Acc: 69.49%)\n",
      "\n",
      "========= Epoch 6/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 06/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:52<00:00, 13.87it/s, acc=81.78%, loss=0.9057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 06/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:15<00:00, 14.66it/s, acc=61.41%, loss=1.2616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.9057 | Acc: 81.78%\n",
      "  Eyes | Loss: 1.2616 | Acc: 61.41%\n",
      "  Avg Acc: 71.59%\n",
      "  üíæ Saved best model! (Epoch 6 | Avg Acc: 71.59%)\n",
      "\n",
      "========= Epoch 7/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 07/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:37<00:00,  9.93it/s, acc=83.92%, loss=0.8644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 07/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:06<00:00, 15.36it/s, acc=62.68%, loss=1.2285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.8644 | Acc: 83.92%\n",
      "  Eyes | Loss: 1.2285 | Acc: 62.68%\n",
      "  Avg Acc: 73.30%\n",
      "  üíæ Saved best model! (Epoch 7 | Avg Acc: 73.30%)\n",
      "\n",
      "========= Epoch 8/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 08/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:26<00:00, 10.66it/s, acc=85.55%, loss=0.8315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 08/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:17<00:00, 14.55it/s, acc=63.86%, loss=1.1980]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.8315 | Acc: 85.55%\n",
      "  Eyes | Loss: 1.1980 | Acc: 63.86%\n",
      "  Avg Acc: 74.70%\n",
      "  üíæ Saved best model! (Epoch 8 | Avg Acc: 74.70%)\n",
      "\n",
      "========= Epoch 9/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 09/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:57<00:00, 13.32it/s, acc=87.20%, loss=0.8011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 09/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:24<00:00, 14.03it/s, acc=64.79%, loss=1.1727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.8011 | Acc: 87.20%\n",
      "  Eyes | Loss: 1.1727 | Acc: 64.79%\n",
      "  Avg Acc: 75.99%\n",
      "  üíæ Saved best model! (Epoch 9 | Avg Acc: 75.99%)\n",
      "\n",
      "========= Epoch 10/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 10/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:08<00:00, 12.19it/s, acc=88.43%, loss=0.7778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 10/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:08<00:00, 15.20it/s, acc=65.43%, loss=1.1539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.7778 | Acc: 88.43%\n",
      "  Eyes | Loss: 1.1539 | Acc: 65.43%\n",
      "  Avg Acc: 76.93%\n",
      "  üíæ Saved best model! (Epoch 10 | Avg Acc: 76.93%)\n",
      "\n",
      "========= Epoch 11/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 11/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:25<00:00, 10.71it/s, acc=89.74%, loss=0.7509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 11/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:03<00:00, 15.66it/s, acc=66.22%, loss=1.1366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.7509 | Acc: 89.74%\n",
      "  Eyes | Loss: 1.1366 | Acc: 66.22%\n",
      "  Avg Acc: 77.98%\n",
      "  üíæ Saved best model! (Epoch 11 | Avg Acc: 77.98%)\n",
      "\n",
      "========= Epoch 12/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 12/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:34<00:00, 10.13it/s, acc=90.66%, loss=0.7338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 12/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:12<00:00, 14.89it/s, acc=66.99%, loss=1.1182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.7338 | Acc: 90.66%\n",
      "  Eyes | Loss: 1.1182 | Acc: 66.99%\n",
      "  Avg Acc: 78.82%\n",
      "  üíæ Saved best model! (Epoch 12 | Avg Acc: 78.82%)\n",
      "\n",
      "========= Epoch 13/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 13/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:24<00:00, 10.84it/s, acc=91.95%, loss=0.7091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 13/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:17<00:00, 14.51it/s, acc=67.53%, loss=1.1034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.7091 | Acc: 91.95%\n",
      "  Eyes | Loss: 1.1034 | Acc: 67.53%\n",
      "  Avg Acc: 79.74%\n",
      "  üíæ Saved best model! (Epoch 13 | Avg Acc: 79.74%)\n",
      "\n",
      "========= Epoch 14/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 14/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:56<00:00, 13.37it/s, acc=92.26%, loss=0.7012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 14/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:22<00:00, 14.17it/s, acc=67.78%, loss=1.0915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.7012 | Acc: 92.26%\n",
      "  Eyes | Loss: 1.0915 | Acc: 67.78%\n",
      "  Avg Acc: 80.02%\n",
      "  üíæ Saved best model! (Epoch 14 | Avg Acc: 80.02%)\n",
      "\n",
      "========= Epoch 15/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 15/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:07<00:00, 12.25it/s, acc=93.11%, loss=0.6832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 15/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:11<00:00, 15.03it/s, acc=68.44%, loss=1.0779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6832 | Acc: 93.11%\n",
      "  Eyes | Loss: 1.0779 | Acc: 68.44%\n",
      "  Avg Acc: 80.77%\n",
      "  üíæ Saved best model! (Epoch 15 | Avg Acc: 80.77%)\n",
      "\n",
      "========= Epoch 16/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 16/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:24<00:00, 10.85it/s, acc=93.75%, loss=0.6664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 16/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:01<00:00, 15.79it/s, acc=68.84%, loss=1.0664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6664 | Acc: 93.75%\n",
      "  Eyes | Loss: 1.0664 | Acc: 68.84%\n",
      "  Avg Acc: 81.30%\n",
      "  üíæ Saved best model! (Epoch 16 | Avg Acc: 81.30%)\n",
      "\n",
      "========= Epoch 17/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 17/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:30<00:00, 10.38it/s, acc=94.19%, loss=0.6597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 17/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:11<00:00, 14.97it/s, acc=69.20%, loss=1.0561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6597 | Acc: 94.19%\n",
      "  Eyes | Loss: 1.0561 | Acc: 69.20%\n",
      "  Avg Acc: 81.70%\n",
      "  üíæ Saved best model! (Epoch 17 | Avg Acc: 81.70%)\n",
      "\n",
      "========= Epoch 18/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 18/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:17<00:00, 11.34it/s, acc=94.61%, loss=0.6476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 18/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:14<00:00, 14.78it/s, acc=69.49%, loss=1.0453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6476 | Acc: 94.61%\n",
      "  Eyes | Loss: 1.0453 | Acc: 69.49%\n",
      "  Avg Acc: 82.05%\n",
      "  üíæ Saved best model! (Epoch 18 | Avg Acc: 82.05%)\n",
      "\n",
      "========= Epoch 19/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 19/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:13<00:00, 11.68it/s, acc=94.97%, loss=0.6400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 19/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:21<00:00, 14.22it/s, acc=69.61%, loss=1.0376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6400 | Acc: 94.97%\n",
      "  Eyes | Loss: 1.0376 | Acc: 69.61%\n",
      "  Avg Acc: 82.29%\n",
      "  üíæ Saved best model! (Epoch 19 | Avg Acc: 82.29%)\n",
      "\n",
      "========= Epoch 20/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 20/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:05<00:00, 12.41it/s, acc=95.42%, loss=0.6278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 20/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:12<00:00, 14.92it/s, acc=70.20%, loss=1.0279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6278 | Acc: 95.42%\n",
      "  Eyes | Loss: 1.0279 | Acc: 70.20%\n",
      "  Avg Acc: 82.81%\n",
      "  üíæ Saved best model! (Epoch 20 | Avg Acc: 82.81%)\n",
      "\n",
      "========= Epoch 21/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 21/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:21<00:00, 11.01it/s, acc=95.76%, loss=0.6212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 21/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:11<00:00, 15.00it/s, acc=70.64%, loss=1.0187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6212 | Acc: 95.76%\n",
      "  Eyes | Loss: 1.0187 | Acc: 70.64%\n",
      "  Avg Acc: 83.20%\n",
      "  üíæ Saved best model! (Epoch 21 | Avg Acc: 83.20%)\n",
      "\n",
      "========= Epoch 22/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 22/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:33<00:00, 10.16it/s, acc=95.99%, loss=0.6146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 22/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:05<00:00, 15.47it/s, acc=70.73%, loss=1.0113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6146 | Acc: 95.99%\n",
      "  Eyes | Loss: 1.0113 | Acc: 70.73%\n",
      "  Avg Acc: 83.36%\n",
      "  üíæ Saved best model! (Epoch 22 | Avg Acc: 83.36%)\n",
      "\n",
      "========= Epoch 23/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 23/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:32<00:00, 10.26it/s, acc=96.17%, loss=0.6089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 23/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:12<00:00, 14.94it/s, acc=71.07%, loss=1.0055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6089 | Acc: 96.17%\n",
      "  Eyes | Loss: 1.0055 | Acc: 71.07%\n",
      "  Avg Acc: 83.62%\n",
      "  üíæ Saved best model! (Epoch 23 | Avg Acc: 83.62%)\n",
      "\n",
      "========= Epoch 24/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 24/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:22<00:00, 10.97it/s, acc=96.49%, loss=0.6023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 24/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:19<00:00, 14.41it/s, acc=71.27%, loss=0.9975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.6023 | Acc: 96.49%\n",
      "  Eyes | Loss: 0.9975 | Acc: 71.27%\n",
      "  Avg Acc: 83.88%\n",
      "  üíæ Saved best model! (Epoch 24 | Avg Acc: 83.88%)\n",
      "\n",
      "========= Epoch 25/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 25/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:18<00:00, 11.25it/s, acc=96.87%, loss=0.5937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 25/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:22<00:00, 14.16it/s, acc=71.46%, loss=0.9916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5937 | Acc: 96.87%\n",
      "  Eyes | Loss: 0.9916 | Acc: 71.46%\n",
      "  Avg Acc: 84.17%\n",
      "  üíæ Saved best model! (Epoch 25 | Avg Acc: 84.17%)\n",
      "\n",
      "========= Epoch 26/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 26/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:11<00:00, 11.85it/s, acc=96.89%, loss=0.5904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 26/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:24<00:00, 14.03it/s, acc=71.68%, loss=0.9840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5904 | Acc: 96.89%\n",
      "  Eyes | Loss: 0.9840 | Acc: 71.68%\n",
      "  Avg Acc: 84.28%\n",
      "  üíæ Saved best model! (Epoch 26 | Avg Acc: 84.28%)\n",
      "\n",
      "========= Epoch 27/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 27/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:07<00:00, 12.28it/s, acc=97.14%, loss=0.5829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 27/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:10<00:00, 15.07it/s, acc=71.91%, loss=0.9795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5829 | Acc: 97.14%\n",
      "  Eyes | Loss: 0.9795 | Acc: 71.91%\n",
      "  Avg Acc: 84.52%\n",
      "  üíæ Saved best model! (Epoch 27 | Avg Acc: 84.52%)\n",
      "\n",
      "========= Epoch 28/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 28/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:33<00:00, 10.19it/s, acc=97.39%, loss=0.5785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 28/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:06<00:00, 15.38it/s, acc=72.02%, loss=0.9738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5785 | Acc: 97.39%\n",
      "  Eyes | Loss: 0.9738 | Acc: 72.02%\n",
      "  Avg Acc: 84.71%\n",
      "  üíæ Saved best model! (Epoch 28 | Avg Acc: 84.71%)\n",
      "\n",
      "========= Epoch 29/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 29/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:41<00:00,  9.65it/s, acc=97.59%, loss=0.5741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 29/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:04<00:00, 15.58it/s, acc=72.34%, loss=0.9656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5741 | Acc: 97.59%\n",
      "  Eyes | Loss: 0.9656 | Acc: 72.34%\n",
      "  Avg Acc: 84.97%\n",
      "  üíæ Saved best model! (Epoch 29 | Avg Acc: 84.97%)\n",
      "\n",
      "========= Epoch 30/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 30/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:25<00:00, 10.76it/s, acc=97.68%, loss=0.5705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 30/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:12<00:00, 14.89it/s, acc=72.45%, loss=0.9626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5705 | Acc: 97.68%\n",
      "  Eyes | Loss: 0.9626 | Acc: 72.45%\n",
      "  Avg Acc: 85.06%\n",
      "  üíæ Saved best model! (Epoch 30 | Avg Acc: 85.06%)\n",
      "\n",
      "========= Epoch 31/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 31/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:16<00:00, 11.44it/s, acc=97.84%, loss=0.5660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 31/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:17<00:00, 14.54it/s, acc=72.69%, loss=0.9569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5660 | Acc: 97.84%\n",
      "  Eyes | Loss: 0.9569 | Acc: 72.69%\n",
      "  Avg Acc: 85.26%\n",
      "  üíæ Saved best model! (Epoch 31 | Avg Acc: 85.26%)\n",
      "\n",
      "========= Epoch 32/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 32/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:04<00:00, 12.55it/s, acc=97.98%, loss=0.5623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 32/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:16<00:00, 14.57it/s, acc=72.76%, loss=0.9521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5623 | Acc: 97.98%\n",
      "  Eyes | Loss: 0.9521 | Acc: 72.76%\n",
      "  Avg Acc: 85.37%\n",
      "  üíæ Saved best model! (Epoch 32 | Avg Acc: 85.37%)\n",
      "\n",
      "========= Epoch 33/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 33/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:10<00:00, 11.99it/s, acc=98.09%, loss=0.5587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 33/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:10<00:00, 15.08it/s, acc=73.03%, loss=0.9480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5587 | Acc: 98.09%\n",
      "  Eyes | Loss: 0.9480 | Acc: 73.03%\n",
      "  Avg Acc: 85.56%\n",
      "  üíæ Saved best model! (Epoch 33 | Avg Acc: 85.56%)\n",
      "\n",
      "========= Epoch 34/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 34/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:29<00:00, 10.46it/s, acc=98.18%, loss=0.5567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 34/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:06<00:00, 15.38it/s, acc=73.21%, loss=0.9447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5567 | Acc: 98.18%\n",
      "  Eyes | Loss: 0.9447 | Acc: 73.21%\n",
      "  Avg Acc: 85.69%\n",
      "  üíæ Saved best model! (Epoch 34 | Avg Acc: 85.69%)\n",
      "\n",
      "========= Epoch 35/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 35/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:46<00:00,  9.38it/s, acc=98.24%, loss=0.5533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 35/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:06<00:00, 15.43it/s, acc=73.26%, loss=0.9403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5533 | Acc: 98.24%\n",
      "  Eyes | Loss: 0.9403 | Acc: 73.26%\n",
      "  Avg Acc: 85.75%\n",
      "  üíæ Saved best model! (Epoch 35 | Avg Acc: 85.75%)\n",
      "\n",
      "========= Epoch 36/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 36/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:25<00:00, 10.74it/s, acc=98.35%, loss=0.5505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 36/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:10<00:00, 15.06it/s, acc=73.47%, loss=0.9371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5505 | Acc: 98.35%\n",
      "  Eyes | Loss: 0.9371 | Acc: 73.47%\n",
      "  Avg Acc: 85.91%\n",
      "  üíæ Saved best model! (Epoch 36 | Avg Acc: 85.91%)\n",
      "\n",
      "========= Epoch 37/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 37/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:23<00:00, 10.89it/s, acc=98.40%, loss=0.5491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 37/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:17<00:00, 14.51it/s, acc=73.59%, loss=0.9337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5491 | Acc: 98.40%\n",
      "  Eyes | Loss: 0.9337 | Acc: 73.59%\n",
      "  Avg Acc: 85.99%\n",
      "  üíæ Saved best model! (Epoch 37 | Avg Acc: 85.99%)\n",
      "\n",
      "========= Epoch 38/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 38/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:06<00:00, 12.36it/s, acc=98.56%, loss=0.5461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 38/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [03:22<00:00, 14.16it/s, acc=73.73%, loss=0.9297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5461 | Acc: 98.56%\n",
      "  Eyes | Loss: 0.9297 | Acc: 73.73%\n",
      "  Avg Acc: 86.15%\n",
      "  üíæ Saved best model! (Epoch 38 | Avg Acc: 86.15%)\n",
      "\n",
      "========= Epoch 39/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 39/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [02:05<00:00, 12.43it/s, acc=98.58%, loss=0.5445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 39/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:51<00:00, 16.71it/s, acc=73.91%, loss=0.9283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5445 | Acc: 98.58%\n",
      "  Eyes | Loss: 0.9283 | Acc: 73.91%\n",
      "  Avg Acc: 86.25%\n",
      "  üíæ Saved best model! (Epoch 39 | Avg Acc: 86.25%)\n",
      "\n",
      "========= Epoch 40/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 40/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:40<00:00, 15.50it/s, acc=98.63%, loss=0.5435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 40/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:46<00:00, 17.27it/s, acc=73.96%, loss=0.9246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5435 | Acc: 98.63%\n",
      "  Eyes | Loss: 0.9246 | Acc: 73.96%\n",
      "  Avg Acc: 86.30%\n",
      "  üíæ Saved best model! (Epoch 40 | Avg Acc: 86.30%)\n",
      "\n",
      "========= Epoch 41/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 41/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:44<00:00, 15.02it/s, acc=98.66%, loss=0.5424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 41/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:42<00:00, 17.69it/s, acc=74.17%, loss=0.9220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5424 | Acc: 98.66%\n",
      "  Eyes | Loss: 0.9220 | Acc: 74.17%\n",
      "  Avg Acc: 86.42%\n",
      "  üíæ Saved best model! (Epoch 41 | Avg Acc: 86.42%)\n",
      "\n",
      "========= Epoch 42/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 42/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:49<00:00, 14.28it/s, acc=98.72%, loss=0.5407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 42/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:40<00:00, 17.88it/s, acc=74.31%, loss=0.9192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5407 | Acc: 98.72%\n",
      "  Eyes | Loss: 0.9192 | Acc: 74.31%\n",
      "  Avg Acc: 86.52%\n",
      "  üíæ Saved best model! (Epoch 42 | Avg Acc: 86.52%)\n",
      "\n",
      "========= Epoch 43/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 43/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:47<00:00, 14.47it/s, acc=98.73%, loss=0.5397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 43/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:40<00:00, 17.91it/s, acc=74.28%, loss=0.9179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5397 | Acc: 98.73%\n",
      "  Eyes | Loss: 0.9179 | Acc: 74.28%\n",
      "  Avg Acc: 86.51%\n",
      "\n",
      "========= Epoch 44/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 44/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:47<00:00, 14.54it/s, acc=98.80%, loss=0.5385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 44/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:40<00:00, 17.87it/s, acc=74.38%, loss=0.9167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5385 | Acc: 98.80%\n",
      "  Eyes | Loss: 0.9167 | Acc: 74.38%\n",
      "  Avg Acc: 86.59%\n",
      "  üíæ Saved best model! (Epoch 44 | Avg Acc: 86.59%)\n",
      "\n",
      "========= Epoch 45/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 45/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:42<00:00, 15.18it/s, acc=98.83%, loss=0.5377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 45/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:52<00:00, 16.68it/s, acc=74.50%, loss=0.9154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5377 | Acc: 98.83%\n",
      "  Eyes | Loss: 0.9154 | Acc: 74.50%\n",
      "  Avg Acc: 86.66%\n",
      "  üíæ Saved best model! (Epoch 45 | Avg Acc: 86.66%)\n",
      "\n",
      "========= Epoch 46/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 46/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:45<00:00, 14.82it/s, acc=98.77%, loss=0.5375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 46/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:50<00:00, 16.81it/s, acc=74.62%, loss=0.9141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5375 | Acc: 98.77%\n",
      "  Eyes | Loss: 0.9141 | Acc: 74.62%\n",
      "  Avg Acc: 86.70%\n",
      "  üíæ Saved best model! (Epoch 46 | Avg Acc: 86.70%)\n",
      "\n",
      "========= Epoch 47/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 47/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:46<00:00, 14.71it/s, acc=98.85%, loss=0.5367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 47/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:51<00:00, 16.79it/s, acc=74.54%, loss=0.9122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5367 | Acc: 98.85%\n",
      "  Eyes | Loss: 0.9122 | Acc: 74.54%\n",
      "  Avg Acc: 86.69%\n",
      "\n",
      "========= Epoch 48/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 48/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:47<00:00, 14.55it/s, acc=98.86%, loss=0.5368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 48/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:50<00:00, 16.81it/s, acc=74.57%, loss=0.9115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5368 | Acc: 98.86%\n",
      "  Eyes | Loss: 0.9115 | Acc: 74.57%\n",
      "  Avg Acc: 86.71%\n",
      "  üíæ Saved best model! (Epoch 48 | Avg Acc: 86.71%)\n",
      "\n",
      "========= Epoch 49/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 49/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:48<00:00, 14.38it/s, acc=98.92%, loss=0.5356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 49/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:51<00:00, 16.73it/s, acc=74.73%, loss=0.9116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5356 | Acc: 98.92%\n",
      "  Eyes | Loss: 0.9116 | Acc: 74.73%\n",
      "  Avg Acc: 86.83%\n",
      "  üíæ Saved best model! (Epoch 49 | Avg Acc: 86.83%)\n",
      "\n",
      "========= Epoch 50/50 =========\n",
      "\n",
      "[1/2] Skin Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Skin ] Epoch 50/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [01:46<00:00, 14.61it/s, acc=98.87%, loss=0.5361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Eyes Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [Eyes ] Epoch 50/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2871/2871 [02:51<00:00, 16.70it/s, acc=74.65%, loss=0.9121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skin | Loss: 0.5361 | Acc: 98.87%\n",
      "  Eyes | Loss: 0.9121 | Acc: 74.65%\n",
      "  Avg Acc: 86.76%\n",
      "\n",
      "üèÜ Training Finished. Best Epoch: 49 | Best Avg Acc: 86.83%\n",
      "‚Üí3Ô∏è‚É£  Generating training history plot...\n",
      "  ‚úÖ Saved: anomaly_training_history.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 24\n",
    "LR = 1e-4\n",
    "NUM_IMAGES_PER_SAMPLE = 5          # ÏÇ¨Ïö©ÏûêÍ∞Ä ÏóÖÎ°úÎìúÌïòÎäî ÏÇ¨ÏßÑ Ïàò\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# CLASS DEFINITIONS\n",
    "# Í∑úÏπô: dog_ Ï†ëÎëê ‚Üí dog classes, cat_ Ï†ëÎëê ‚Üí cat classes\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# ‚îÄ‚îÄ 4_Animal_Skin ‚îÄ‚îÄ\n",
    "SKIN_CLASSES = [\n",
    "    \"cat_normal\", \"cat_Í≤∞Ï†à,Ï¢ÖÍ¥¥\", \"cat_ÎÜçÌè¨,Ïó¨ÎìúÎ¶Ñ\",\n",
    "    \"cat_ÎπÑÎì¨,Í∞ÅÏßà,ÏÉÅÌîºÏÑ±ÏûîÍ≥†Î¶¨\", \"dog_normal\",\n",
    "    \"dog_Í≤∞Ï†à,Ï¢ÖÍ¥¥\", \"dog_ÎÜçÌè¨,Ïó¨ÎìúÎ¶Ñ\", \"dog_ÎØ∏ÎûÄ,Í∂§Ïñë\",\n",
    "    \"dog_ÎπÑÎì¨,Í∞ÅÏßà,ÏÉÅÌîºÏÑ±ÏûîÍ≥†Î¶¨\", \"dog_ÎπÑÎì¨,Í∞ÅÏßà,ÏÉÅÌîºÏÑ±ÏûîÍ≥†Î¶¨\",\n",
    "]\n",
    "\n",
    "# ‚îÄ‚îÄ 5_Animal_Eyes ‚îÄ‚îÄ\n",
    "EYES_CLASSES = [\n",
    "    \"cat_normal\", \"cat_Í∞ÅÎßâÍ∂§Ïñë\", \"cat_Í∞ÅÎßâÎ∂ÄÍ≥®Ìé∏\",\n",
    "    \"cat_Í≤∞ÎßâÏóº\", \"cat_ÎπÑÍ∂§ÏñëÏÑ±Í∞ÅÎßâÏóº\", \"cat_ÏïàÍ≤ÄÏóº\",\n",
    "    \"dog_normal\", \"dog_Í≤∞ÎßâÏóº\", \"dog_Í∂§ÏñëÏÑ±Í∞ÅÎßâÏßàÌôò_ÏÉÅ\",\n",
    "    \"dog_Í∂§ÏñëÏÑ±Í∞ÅÎßâÏßàÌôò_Ìïò\", \"dog_Î∞±ÎÇ¥Ïû•_ÎπÑÏÑ±Ïàô\", \"dog_Î∞±ÎÇ¥Ïû•_ÏÑ±Ïàô\",\n",
    "    \"dog_Î∞±ÎÇ¥Ïû•_Ï¥àÍ∏∞\", \"dog_ÎπÑÍ∂§ÏñëÏÑ±Í∞ÅÎßâÏßàÌôò_ÏÉÅ\", \"dog_ÎπÑÍ∂§ÏñëÏÑ±Í∞ÅÎßâÏßàÌôò_Ìïò\",\n",
    "    \"dog_ÏÉâÏÜåÏπ®Ï∞©ÏÑ±Í∞ÅÎßâÏóº\", \"dog_ÏïàÍ≤ÄÎÇ¥Î∞òÏ¶ù\", \"dog_ÏïàÍ≤ÄÏóº\",\n",
    "    \"dog_ÏïàÍ≤ÄÏ¢ÖÏñë\", \"dog_Ïú†Î£®Ï¶ù\", \"dog_ÌïµÍ≤ΩÌôî\"\n",
    "]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Ïú†ÏÇ¨ ÌÅ¥ÎûòÏä§ Í∑∏Î£π Ï†ïÏùò (Eyes Ï†ÑÏö©)\n",
    "# ÎèôÏùº ÏßàÌôò ÎÇ¥ ÏÑ∏Î∂ÑÎ•òÎäî Hierarchical Loss Í∞ÄÏ§ëÏπòÎ°ú ÌòºÎèô Ìå®ÎÑêÌã∞Î•º Ï§å\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EYES_SIMILAR_GROUPS = [\n",
    "    [\"dog_ÎπÑÍ∂§ÏñëÏÑ±Í∞ÅÎßâÏßàÌôò_ÏÉÅ\", \"dog_ÎπÑÍ∂§ÏñëÏÑ±Í∞ÅÎßâÏßàÌôò_Ìïò\"],\n",
    "    [\"dog_Í∂§ÏñëÏÑ±Í∞ÅÎßâÏßàÌôò_ÏÉÅ\", \"dog_Í∂§ÏñëÏÑ±Í∞ÅÎßâÏßàÌôò_Ìïò\"],\n",
    "    [\"dog_Î∞±ÎÇ¥Ïû•_Ï¥àÍ∏∞\", \"dog_Î∞±ÎÇ¥Ïû•_ÎπÑÏÑ±Ïàô\", \"dog_Î∞±ÎÇ¥Ïû•_ÏÑ±Ïàô\"],\n",
    "]\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# LOSS: Hierarchical-Aware CE\n",
    "# ===============================\n",
    "# Í∞ôÏùÄ ÏßàÌôò Í∑∏Î£π ÎÇ¥ Ïò§Î∂ÑÎ•òÏóê extra_penalty Î•º Í≥±Ìï¥\n",
    "# Î™®Îç∏Ïù¥ ÏÉÅ/Ìïò, Ï¥àÍ∏∞/ÏÑ±Ïàô Íµ¨Î∂ÑÏùÑ Îçî Ïó¥Ïã¨Ìûà ÌïôÏäµÌïòÍ≤å ÎßåÎì†Îã§.\n",
    "\n",
    "class HierarchicalWeightedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    CrossEntropyLoss + Label Smoothing + Ïú†ÏÇ¨ ÌÅ¥ÎûòÏä§ ÌòºÎèô ÌéòÎÑêÌã∞\n",
    "\n",
    "    Args:\n",
    "        class_names    : ÌïôÏäµ taskÏóê Ìï¥ÎãπÌïòÎäî ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ Î¶¨Ïä§Ìä∏\n",
    "        similar_groups : Ïú†ÏÇ¨ ÌÅ¥ÎûòÏä§ Î¨∂Ïùå [[cls_a, cls_b], ...]\n",
    "        class_weights  : ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Î≥¥Ï†ï weight ÌÖêÏÑú\n",
    "        smoothing      : label smoothing Œµ\n",
    "        extra_penalty  : Í∞ôÏùÄ Í∑∏Î£π ÎÇ¥ Ïò§Î∂ÑÎ•ò Ïãú loss Î∞∞Ïú®\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        class_names,\n",
    "        similar_groups=None,\n",
    "        class_weights=None,\n",
    "        smoothing=LABEL_SMOOTHING,\n",
    "        extra_penalty=1.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.smoothing      = smoothing\n",
    "        self.extra_penalty  = extra_penalty\n",
    "        self.num_classes    = len(class_names)\n",
    "        self.class_names    = class_names\n",
    "        self.name_to_idx    = {n: i for i, n in enumerate(class_names)}\n",
    "\n",
    "        # Ïú†ÏÇ¨ Í∑∏Î£π ‚Üí (idx_i, idx_j) pair set\n",
    "        self.penalty_pairs = set()\n",
    "        if similar_groups:\n",
    "            for group in similar_groups:\n",
    "                idxs = [self.name_to_idx[n] for n in group if n in self.name_to_idx]\n",
    "                for i in range(len(idxs)):\n",
    "                    for j in range(i + 1, len(idxs)):\n",
    "                        self.penalty_pairs.add((idxs[i], idxs[j]))\n",
    "                        self.penalty_pairs.add((idxs[j], idxs[i]))\n",
    "\n",
    "        self.register_buffer(\"weight\", class_weights)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        logits  : (B, C)\n",
    "        targets : (B,)  long\n",
    "        \"\"\"\n",
    "        B, C = logits.shape\n",
    "        device = logits.device\n",
    "\n",
    "        # ‚îÄ‚îÄ Label Smoothing ‚îÄ‚îÄ\n",
    "        log_prob = F.log_softmax(logits, dim=-1)\n",
    "        smooth_loss = -log_prob.mean(dim=-1)                              # (B,)\n",
    "        nll_loss    = F.nll_loss(log_prob, targets, weight=self.weight, reduction=\"none\")  # (B,)\n",
    "        base_loss   = (1 - self.smoothing) * nll_loss + self.smoothing * smooth_loss  # (B,)\n",
    "\n",
    "        # ‚îÄ‚îÄ Hierarchical Penalty ‚îÄ‚îÄ\n",
    "        if self.penalty_pairs:\n",
    "            pred_classes = logits.argmax(dim=-1)          # (B,)\n",
    "            penalty_mask = torch.ones(B, device=device)\n",
    "            for b in range(B):\n",
    "                t = targets[b].item()\n",
    "                p = pred_classes[b].item()\n",
    "                if (t, p) in self.penalty_pairs:\n",
    "                    penalty_mask[b] = self.extra_penalty\n",
    "            base_loss = base_loss * penalty_mask\n",
    "\n",
    "        return base_loss.mean()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# CLASS WEIGHT COMPUTATION\n",
    "# ===============================\n",
    "\n",
    "def compute_class_weights(sample_counts: dict, class_names: list) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Inverse-frequency Î∞©ÏãùÏúºÎ°ú ÌÅ¥ÎûòÏä§ Í∞ÄÏ§ëÏπòÎ•º Í≥ÑÏÇ∞ÌïúÎã§.\n",
    "    sample_counts: {class_name: n_samples}\n",
    "    \"\"\"\n",
    "    counts = torch.tensor(\n",
    "        [sample_counts.get(n, 1) for n in class_names], dtype=torch.float\n",
    "    )\n",
    "    weights = 1.0 / counts\n",
    "    weights = weights / weights.sum() * len(class_names)   # normalize\n",
    "    return weights\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# MODEL DEFINITIONS\n",
    "# ===============================\n",
    "\n",
    "class AnomalyMultiBackbone(nn.Module):\n",
    "    \"\"\"\n",
    "    Ïù¥ÏÉÅ Ï¶ùÏÉÅ Omni Î™®Îç∏\n",
    "    ‚îú‚îÄ‚îÄ skin_backbone  ‚Üí Skin Î∂ÑÎ•ò (ÌîºÎ∂ÄÏßàÌôò)\n",
    "    ‚îî‚îÄ‚îÄ eyes_backbone  ‚Üí Eyes Î∂ÑÎ•ò (ÏïàÍµ¨ÏßàÌôò)\n",
    "\n",
    "    Í∞Å backbone ÏùÄ ResNet50 (ImageNet pretrained) ÏùÑ Í∏∞Î∞òÏúºÎ°ú ÌïòÎ©∞,\n",
    "    ÎßàÏßÄÎßâ fc Î•º task-specific head Î°ú ÍµêÏ≤¥ÌïúÎã§.\n",
    "\n",
    "    Eyes Ïùò Í≤ΩÏö∞ Ïú†ÏÇ¨ ÌÅ¥ÎûòÏä§ ÌòºÎèôÏùÑ Ï§ÑÏù¥Í∏∞ ÏúÑÌï¥:\n",
    "      1) Dropout + Îçî ÍπäÏùÄ head\n",
    "      2) Feature Attention (Channel Squeeze-Excitation)\n",
    "    ÏùÑ Ï∂îÍ∞ÄÌïúÎã§.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_skin_classes: int, num_eyes_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # ‚îÄ‚îÄ Skin Backbone (ResNet50 pretrained) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        skin_base = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        skin_feat_dim = skin_base.fc.in_features          # 2048\n",
    "        skin_base.fc = nn.Identity()\n",
    "        self.skin_backbone = skin_base\n",
    "        self.skin_head = nn.Sequential(\n",
    "            nn.Linear(skin_feat_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_skin_classes),\n",
    "        )\n",
    "\n",
    "        # ‚îÄ‚îÄ Eyes Backbone (ResNet50 pretrained + SE attention) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        eyes_base = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        eyes_feat_dim = eyes_base.fc.in_features\n",
    "        eyes_base.fc = nn.Identity()\n",
    "        self.eyes_backbone = eyes_base\n",
    "\n",
    "        # Squeeze-Excitation: Ï±ÑÎÑê Ï§ëÏöîÎèÑ Ïû¨Î≥¥Ï†ï ‚Üí ÎØ∏ÏÑ∏Ìïú Î≥ëÎ≥Ä Íµ¨Î∂ÑÎ†• Ìñ•ÏÉÅ\n",
    "        self.eyes_se = SqueezeExcitation(eyes_feat_dim, reduction=16)\n",
    "\n",
    "        # Îçî ÍπäÏùÄ classifier head\n",
    "        self.eyes_head = nn.Sequential(\n",
    "            nn.Linear(eyes_feat_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_eyes_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, task: str = \"skin\") -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x    : (B, 3, 224, 224)  ‚Äî Îã®Ïùº Ïù¥ÎØ∏ÏßÄ ÎòêÎäî ÏïôÏÉÅÎ∏î ÌõÑ ÌèâÍ∑† logit Ïö©\n",
    "        task : \"skin\" | \"eyes\"\n",
    "        \"\"\"\n",
    "        if task == \"skin\":\n",
    "            feat = self.skin_backbone(x)\n",
    "            return self.skin_head(feat)\n",
    "\n",
    "        elif task == \"eyes\":\n",
    "            feat = self.eyes_backbone(x)           # (B, 2048)\n",
    "            feat = self.eyes_se(feat)              # channel attention\n",
    "            return self.eyes_head(feat)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task: {task!r}. Choose 'skin' or 'eyes'.\")\n",
    "\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    \"\"\"\n",
    "    1-D Squeeze-Excitation for feature vectors (after global avg pool).\n",
    "    feat : (B, C)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self.se(x)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# INFERENCE: 5-Image Ensemble\n",
    "# ===============================\n",
    "\n",
    "def predict_anomaly(\n",
    "    model: AnomalyMultiBackbone,\n",
    "    images: list,           # list of PIL.Image (5Ïû•)\n",
    "    task: str,              # \"skin\" | \"eyes\"\n",
    "    pet_type: str,          # \"dog\" | \"cat\"\n",
    "    class_names: list,\n",
    "    device=DEVICE,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    5Ïû•Ïùò Ïù¥ÎØ∏ÏßÄÎ•º ÏûÖÎ†•Î∞õÏïÑ ÌèâÍ∑† softmax ÌôïÎ•†Î°ú ÏµúÏ¢Ö ÏòàÏ∏°ÏùÑ Î∞òÌôòÌïúÎã§.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            \"predicted_class\": str,\n",
    "            \"confidence\": float,\n",
    "            \"top3\": [(class_name, prob), ...]\n",
    "        }\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Î∞òÎ†§ÎèôÎ¨º Ï¢ÖÏóê ÎßûÎäî class indexÎßå ÏÑ†ÌÉù\n",
    "    valid_idxs = [\n",
    "        i for i, n in enumerate(class_names) if n.startswith(pet_type + \"_\")\n",
    "    ]\n",
    "    valid_names = [class_names[i] for i in valid_idxs]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs_accum = torch.zeros(len(class_names), device=device)\n",
    "\n",
    "        for img in images:\n",
    "            tensor = transform(img).unsqueeze(0).to(device)   # (1, 3, 224, 224)\n",
    "            logits = model(tensor, task=task)                  # (1, C)\n",
    "\n",
    "            # Ìï¥Îãπ pet_type Ïô∏ class ÎßàÏä§ÌÇπ (‚àíinf ‚Üí softmax ‚âà 0)\n",
    "            mask = torch.full((len(class_names),), float(\"-inf\"), device=device)\n",
    "            mask[valid_idxs] = logits[0][valid_idxs]\n",
    "\n",
    "            probs = F.softmax(mask, dim=-1)\n",
    "            probs_accum += probs\n",
    "\n",
    "        probs_accum /= len(images)    # ÌèâÍ∑† ÏïôÏÉÅÎ∏î\n",
    "\n",
    "    # Ïú†Ìö® class Ï§ë top-k\n",
    "    valid_probs = [(valid_names[i], probs_accum[valid_idxs[i]].item())\n",
    "                   for i in range(len(valid_idxs))]\n",
    "    valid_probs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return {\n",
    "        \"predicted_class\": valid_probs[0][0],\n",
    "        \"confidence\":      valid_probs[0][1],\n",
    "        \"top3\":            valid_probs[:3],\n",
    "    }\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# DATASETS\n",
    "# ===============================\n",
    "\n",
    "class AnomalyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï°∞:\n",
    "        root_dir/\n",
    "            dog_Í≤∞ÎßâÏóº/  img001.jpg ...\n",
    "            cat_normal/  img001.jpg ...\n",
    "            ...\n",
    "\n",
    "    task      : \"skin\" | \"eyes\"\n",
    "    pet_type  : \"dog\" | \"cat\" | \"all\"\n",
    "    \"\"\"\n",
    "\n",
    "    TRANSFORM = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    TRANSFORM_VAL = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str,\n",
    "        class_names: list,\n",
    "        task: str,\n",
    "        is_train: bool = True,\n",
    "    ):\n",
    "        self.class_names = class_names\n",
    "        self.task        = task\n",
    "        self.transform   = self.TRANSFORM if is_train else self.TRANSFORM_VAL\n",
    "        self.name_to_idx = {n: i for i, n in enumerate(class_names)}\n",
    "\n",
    "        self.samples = []   # [(img_path, label_idx), ...]\n",
    "\n",
    "        for class_name in class_names:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "            label_idx = self.name_to_idx[class_name]\n",
    "            for fname in os.listdir(class_dir):\n",
    "                if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    self.samples.append((os.path.join(class_dir, fname), label_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        return self.transform(img), label\n",
    "\n",
    "    @staticmethod\n",
    "    def get_sample_counts(root_dir: str, class_names: list) -> dict:\n",
    "        counts = {}\n",
    "        for cn in class_names:\n",
    "            d = os.path.join(root_dir, cn)\n",
    "            if os.path.isdir(d):\n",
    "                counts[cn] = len([\n",
    "                    f for f in os.listdir(d)\n",
    "                    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "                ])\n",
    "            else:\n",
    "                counts[cn] = 1\n",
    "        return counts\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# TRAIN FUNCTION\n",
    "# ===============================\n",
    "\n",
    "def train(\n",
    "    skin_root: str = \"files/4_Animal_Skin\",\n",
    "    eyes_root: str = \"files/5_Animal_Eyes\",\n",
    "):\n",
    "    # ‚îÄ‚îÄ ÌÅ¥ÎûòÏä§ Ï†ïÏùò ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    skin_classes = SKIN_CLASSES\n",
    "    eyes_classes = EYES_CLASSES\n",
    "\n",
    "    num_skin  = len(skin_classes)\n",
    "    num_eyes  = len(eyes_classes)\n",
    "\n",
    "    # ‚îÄ‚îÄ Î™®Îç∏ Ï¥àÍ∏∞Ìôî ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    model = AnomalyMultiBackbone(num_skin, num_eyes)\n",
    "\n",
    "    # ‚îÄ‚îÄ ÌÅ¥ÎûòÏä§ Í∞ÄÏ§ëÏπò (Î∂àÍ∑†Ìòï Î≥¥Ï†ï) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    skin_counts  = AnomalyDataset.get_sample_counts(skin_root, skin_classes)\n",
    "    eyes_counts  = AnomalyDataset.get_sample_counts(eyes_root, eyes_classes)\n",
    "\n",
    "    skin_weights = compute_class_weights(skin_counts, skin_classes).to(DEVICE)\n",
    "    eyes_weights = compute_class_weights(eyes_counts, eyes_classes).to(DEVICE)\n",
    "\n",
    "    # ‚îÄ‚îÄ Loss ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    skin_criterion = HierarchicalWeightedLoss(\n",
    "        class_names   = skin_classes,\n",
    "        class_weights = skin_weights,\n",
    "        smoothing     = LABEL_SMOOTHING,\n",
    "    )\n",
    "    eyes_criterion = HierarchicalWeightedLoss(\n",
    "        class_names    = eyes_classes,\n",
    "        similar_groups = EYES_SIMILAR_GROUPS,\n",
    "        class_weights  = eyes_weights,\n",
    "        smoothing      = LABEL_SMOOTHING,\n",
    "        extra_penalty  = 1.5,\n",
    "    )\n",
    "\n",
    "    # ‚îÄ‚îÄ Optimizer & Scheduler ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # ‚îÄ‚îÄ ÌïôÏäµ Í∏∞Î°ù & Best Ï∂îÏ†Å ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    history      = []   # {epoch, skin_loss, skin_acc, eyes_loss, eyes_acc, avg_acc}\n",
    "    best_avg_acc = 0.0\n",
    "    best_epoch   = 0\n",
    "\n",
    "    # ‚îÄ‚îÄ Training Loop ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n========= Epoch {epoch + 1}/{EPOCHS} =========\\n\")\n",
    "\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        # 1Ô∏è‚É£  Skin Training\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        print(\"[1/2] Skin Training\")\n",
    "        model.to(DEVICE)\n",
    "        model.train()\n",
    "\n",
    "        skin_dataset = AnomalyDataset(skin_root, skin_classes, task=\"skin\", is_train=True)\n",
    "        skin_loader  = DataLoader(\n",
    "            skin_dataset,\n",
    "            batch_size  = BATCH_SIZE,\n",
    "            shuffle     = True,\n",
    "            num_workers = NUM_WORKERS,\n",
    "            pin_memory  = True,\n",
    "        )\n",
    "\n",
    "        skin_loss_sum, skin_correct, skin_total = 0.0, 0, 0\n",
    "\n",
    "        skin_pbar = tqdm(skin_loader, desc=f\"  [Skin ] Epoch {epoch+1:02d}/{EPOCHS}\", ncols=110, leave=True)\n",
    "        for images, labels in skin_pbar:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(images, task=\"skin\")\n",
    "                loss    = skin_criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            skin_loss_sum += loss.item() * images.size(0)\n",
    "            skin_correct  += (outputs.argmax(1) == labels).sum().item()\n",
    "            skin_total    += images.size(0)\n",
    "\n",
    "            skin_pbar.set_postfix(\n",
    "                loss=f\"{skin_loss_sum / skin_total:.4f}\",\n",
    "                acc=f\"{100 * skin_correct / skin_total:.2f}%\"\n",
    "            )\n",
    "\n",
    "        del skin_loader, skin_dataset\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        # 2Ô∏è‚É£  Eyes Training\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        print(\"[2/2] Eyes Training\")\n",
    "\n",
    "        eyes_dataset = AnomalyDataset(eyes_root, eyes_classes, task=\"eyes\", is_train=True)\n",
    "        eyes_loader  = DataLoader(\n",
    "            eyes_dataset,\n",
    "            batch_size  = BATCH_SIZE,\n",
    "            shuffle     = True,\n",
    "            num_workers = NUM_WORKERS,\n",
    "            pin_memory  = True,\n",
    "        )\n",
    "\n",
    "        eyes_loss_sum, eyes_correct, eyes_total = 0.0, 0, 0\n",
    "\n",
    "        eyes_pbar = tqdm(eyes_loader, desc=f\"  [Eyes ] Epoch {epoch+1:02d}/{EPOCHS}\", ncols=110, leave=True)\n",
    "        for images, labels in eyes_pbar:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(images, task=\"eyes\")\n",
    "                loss    = eyes_criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            eyes_loss_sum += loss.item() * images.size(0)\n",
    "            eyes_correct  += (outputs.argmax(1) == labels).sum().item()\n",
    "            eyes_total    += images.size(0)\n",
    "\n",
    "            eyes_pbar.set_postfix(\n",
    "                loss=f\"{eyes_loss_sum / eyes_total:.4f}\",\n",
    "                acc=f\"{100 * eyes_correct / eyes_total:.2f}%\"\n",
    "            )\n",
    "\n",
    "        del eyes_loader, eyes_dataset\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # ‚îÄ‚îÄ LR Scheduler Step ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        scheduler.step()\n",
    "\n",
    "        # ‚îÄ‚îÄ History Í∏∞Î°ù ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        skin_epoch_loss = skin_loss_sum / skin_total\n",
    "        skin_epoch_acc  = skin_correct  / skin_total\n",
    "        eyes_epoch_loss = eyes_loss_sum / eyes_total\n",
    "        eyes_epoch_acc  = eyes_correct  / eyes_total\n",
    "        avg_acc         = (skin_epoch_acc + eyes_epoch_acc) / 2\n",
    "\n",
    "        history.append({\n",
    "            'epoch'     : epoch + 1,\n",
    "            'skin_loss' : skin_epoch_loss,\n",
    "            'skin_acc'  : skin_epoch_acc,\n",
    "            'eyes_loss' : eyes_epoch_loss,\n",
    "            'eyes_acc'  : eyes_epoch_acc,\n",
    "            'avg_acc'   : avg_acc,\n",
    "        })\n",
    "\n",
    "        print(f\"  Skin | Loss: {skin_epoch_loss:.4f} | Acc: {skin_epoch_acc*100:.2f}%\")\n",
    "        print(f\"  Eyes | Loss: {eyes_epoch_loss:.4f} | Acc: {eyes_epoch_acc*100:.2f}%\")\n",
    "        print(f\"  Avg Acc: {avg_acc*100:.2f}%\")\n",
    "\n",
    "        # ‚îÄ‚îÄ Best Model Ï†ÄÏû• (avg acc Í∏∞Ï§Ä) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        if avg_acc > best_avg_acc:\n",
    "            best_avg_acc = avg_acc\n",
    "            best_epoch   = epoch + 1\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model\"           : model.state_dict(),\n",
    "                    \"epoch\"           : epoch + 1,\n",
    "                    \"best_avg_acc\"    : best_avg_acc,\n",
    "                    \"skin_classes\"    : SKIN_CLASSES,\n",
    "                    \"eyes_classes\"    : EYES_CLASSES,\n",
    "                    \"history\"         : history,\n",
    "                },\n",
    "                \"pet_abnormal_omni_best.pth\",\n",
    "            )\n",
    "            print(f\"  üíæ Saved best model! (Epoch {best_epoch} | Avg Acc: {best_avg_acc*100:.2f}%)\")\n",
    "\n",
    "\n",
    "    print(f\"\\nüèÜ Training Finished. Best Epoch: {best_epoch} | Best Avg Acc: {best_avg_acc*100:.2f}%\")\n",
    "\n",
    "    # ‚îÄ‚îÄ ÌïôÏäµ Í≥°ÏÑ† ÏãúÍ∞ÅÌôî ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(\"‚Üí3Ô∏è‚É£  Generating training history plot...\")\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    epochs_x     = [h['epoch']     for h in history]\n",
    "    skin_losses  = [h['skin_loss'] for h in history]\n",
    "    eyes_losses  = [h['eyes_loss'] for h in history]\n",
    "    skin_accs    = [h['skin_acc']  for h in history]\n",
    "    eyes_accs    = [h['eyes_acc']  for h in history]\n",
    "    avg_accs     = [h['avg_acc']   for h in history]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # ‚îÄ Loss ‚îÄ\n",
    "    axes[0].plot(epochs_x, skin_losses, 'b-',  linewidth=2, label='Skin Loss')\n",
    "    axes[0].plot(epochs_x, eyes_losses, 'r-',  linewidth=2, label='Eyes Loss')\n",
    "    axes[0].axvline(best_epoch, color='gray', linestyle='--', alpha=0.6, label=f'Best Epoch {best_epoch}')\n",
    "    axes[0].set_title('Training Loss');  axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # ‚îÄ Accuracy ‚îÄ\n",
    "    axes[1].plot(epochs_x, skin_accs, 'b-',  linewidth=2, label='Skin Acc')\n",
    "    axes[1].plot(epochs_x, eyes_accs, 'r-',  linewidth=2, label='Eyes Acc')\n",
    "    axes[1].axvline(best_epoch, color='gray', linestyle='--', alpha=0.6, label=f'Best Epoch {best_epoch}')\n",
    "    axes[1].set_title('Training Accuracy'); axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_ylim(0, 1); axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # ‚îÄ Avg Accuracy ‚îÄ\n",
    "    axes[2].plot(epochs_x, avg_accs, 'g-', linewidth=2, label='Avg Acc')\n",
    "    axes[2].axvline(best_epoch, color='gray', linestyle='--', alpha=0.6, label=f'Best Epoch {best_epoch}')\n",
    "    axes[2].axhline(best_avg_acc, color='green', linestyle=':', alpha=0.6, label=f'Best Acc {best_avg_acc*100:.1f}%')\n",
    "    axes[2].set_title('Average Accuracy');  axes[2].set_xlabel('Epoch'); axes[2].set_ylabel('Accuracy')\n",
    "    axes[2].set_ylim(0, 1); axes[2].legend(); axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle('Anomaly Model Training History', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('anomaly_training_history.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  ‚úÖ Saved: pet_abnormal_omni.png\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# ENTRY POINT\n",
    "# ===============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032db127",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# =========================\n",
    "# Î™®Îç∏ ÌÅ¥ÎûòÏä§ (trainÍ≥º ÎèôÏùº)\n",
    "# =========================\n",
    "class AbnormalityOmni(nn.Module):\n",
    "    def __init__(self, num_classes_per_task):\n",
    "        super().__init__()\n",
    "        self.trunk = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.trunk.fc.in_features\n",
    "        self.trunk.fc = nn.Identity()\n",
    "        \n",
    "        self.pet_head = nn.Linear(in_features, 2)  # dog/cat\n",
    "        \n",
    "        self.task_heads = nn.ModuleDict({\n",
    "            task: nn.Linear(in_features, num_classes) \n",
    "            for task, num_classes in num_classes_per_task.items()\n",
    "        })\n",
    "    \n",
    "    def forward(self, x, task):\n",
    "        if x.dim() == 5:  # 1x5x3x224x224\n",
    "            B = x.size(0)\n",
    "            x = x.view(-1, *x.shape[2:])\n",
    "        \n",
    "        feats = self.trunk(x)\n",
    "        if x.size(0) != feats.size(0):\n",
    "            feats = feats.view(B, -1, feats.size(-1)).mean(1)\n",
    "        \n",
    "        pet_logits = self.pet_head(feats)\n",
    "        task_logits = self.task_heads[task](feats)\n",
    "        \n",
    "        return {\n",
    "            'pet': F.softmax(pet_logits, dim=-1),\n",
    "            task: task_logits\n",
    "        }\n",
    "\n",
    "# =========================\n",
    "# Test Dataset (train ÏùòÏ°¥ÏÑ± Ï†úÍ±∞)\n",
    "# =========================\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, task_dir, label_to_id):\n",
    "        self.samples = []\n",
    "        self.id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "        \n",
    "        for label in os.listdir(task_dir):\n",
    "            if label not in label_to_id:\n",
    "                continue\n",
    "            label_dir = os.path.join(task_dir, label)\n",
    "            for file in os.listdir(label_dir):\n",
    "                if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    self.samples.append((\n",
    "                        os.path.join(label_dir, file),\n",
    "                        label_to_id[label]\n",
    "                    ))\n",
    "        \n",
    "        print(f\"  üìä Test {os.path.basename(task_dir)}: {len(self.samples)} samples\")\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label_id = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, label_id\n",
    "\n",
    "# =========================\n",
    "# Test Ìï®Ïàò\n",
    "# =========================\n",
    "def test():\n",
    "    DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "    BATCH_SIZE = 32  # TestÎäî ÌÅ¨Í≤å\n",
    "    \n",
    "    print(\"üîé Loading best model...\")\n",
    "    checkpoint = torch.load(\"pet_abnormality_omni_best.pth\", map_location=DEVICE)\n",
    "    \n",
    "    num_classes_per_task = checkpoint[\"num_classes_per_task\"]\n",
    "    label_to_id = checkpoint[\"label_to_id\"]\n",
    "    \n",
    "    # Î™®Îç∏ Î≥µÏõê\n",
    "    model = AbnormalityOmni(num_classes_per_task).to(DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"üì¶ Loading TEST datasets...\")\n",
    "    TEST_DIR = os.path.join(\"files\", \"work\", \"abnormality_omni\", \"test\")\n",
    "    tasks = [\"skin\", \"eye\"]\n",
    "    \n",
    "    test_loaders = {}\n",
    "    for task in tasks:\n",
    "        test_loaders[task] = DataLoader(\n",
    "            TestImageDataset(\n",
    "                os.path.join(TEST_DIR, task),\n",
    "                label_to_id[task]\n",
    "            ),\n",
    "            BATCH_SIZE, False, num_workers=8, pin_memory=True\n",
    "        )\n",
    "    \n",
    "    # =========================\n",
    "    # Evaluation\n",
    "    # =========================\n",
    "    results = {}\n",
    "    all_preds = {}\n",
    "    all_labels = {}\n",
    "    \n",
    "    for task in tasks:\n",
    "        print(f\"\\nüîç Testing {task.upper()}...\")\n",
    "        correct, total = 0, 0\n",
    "        all_preds[task] = []\n",
    "        all_labels[task] = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(test_loaders[task], desc=f\"Test {task}\"):\n",
    "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                \n",
    "                outputs = model(imgs, task)\n",
    "                pred = outputs[task].argmax(dim=-1)\n",
    "                \n",
    "                correct += (pred == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                all_preds[task].extend(pred.cpu().numpy())\n",
    "                all_labels[task].extend(labels.cpu().numpy())\n",
    "        \n",
    "        acc = correct / total\n",
    "        results[task] = acc\n",
    "        print(f\"  ‚Üí Accuracy: {acc:.4f} ({acc*100:.1f}%)\")\n",
    "    \n",
    "    # Average\n",
    "    avg_acc = sum(results.values()) / len(tasks)\n",
    "    print(f\"\\nüìä FINAL TEST Results:\")\n",
    "    for task, acc in results.items():\n",
    "        print(f\"  {task.capitalize()}: {acc:.4f} ({acc*100:.1f}%)\")\n",
    "    print(f\"  Average: {avg_acc:.4f} ({avg_acc*100:.1f}%)\")\n",
    "    \n",
    "    # =========================\n",
    "    # Detailed Metrics + Confusion Matrix\n",
    "    # =========================\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for i, task in enumerate(tasks):\n",
    "        plt.subplot(1, len(tasks), i+1)\n",
    "        \n",
    "        # Classification Report\n",
    "        print(f\"\\n{task.upper()} Classification Report:\")\n",
    "        print(classification_report(\n",
    "            all_labels[task], all_preds[task], \n",
    "            target_names=list(label_to_id[task].keys()),\n",
    "            digits=4\n",
    "        ))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(all_labels[task], all_preds[task])\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'{task.capitalize()} Confusion Matrix')\n",
    "        plt.ylabel('True'); plt.xlabel('Pred')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('abnormality_test_results.png', dpi=150, bbox_inches='tight')\n",
    "    # print(\"‚úÖ Saved: abnormality_test_results.png\")\n",
    "    \n",
    "    # Pet prediction accuracy (bonus)\n",
    "    print(\"\\nüîç Pet (dog/cat) Accuracy Check...\")\n",
    "    pet_correct, pet_total = 0, 0\n",
    "    # Ï†ÑÏ≤¥ testÏóêÏÑú pet ÏòàÏ∏° ÏÉòÌîåÎßÅ Ï≤¥ÌÅ¨ (Ïã§Ï†ú appÏ≤òÎüº)\n",
    "    with torch.no_grad():\n",
    "        for task in tasks:\n",
    "            for imgs, _ in test_loaders[task][:5]:  # ÏÉòÌîå\n",
    "                imgs = imgs.to(DEVICE)\n",
    "                pet_probs = model(imgs[:1], task)['pet']  # single img test\n",
    "                pet_pred = pet_probs.argmax().item()\n",
    "                pet_total += 1\n",
    "                # Ïã§Ï†ú pet ÎùºÎ≤® ÏóÜÏúºÎØÄÎ°ú confidenceÎßå\n",
    "                pet_correct += float(pet_probs.max() > 0.8)\n",
    "    \n",
    "    pet_acc = pet_correct / pet_total\n",
    "    print(f\"  Pet classification conf>0.8: {pet_acc:.4f}\")\n",
    "    \n",
    "    # # Save results\n",
    "    # torch.save({\n",
    "    #     'test_results': results,\n",
    "    #     'avg_acc': avg_acc,\n",
    "    #     'predictions': all_preds,\n",
    "    #     'labels': all_labels\n",
    "    # }, \"abnormality_test_results.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
