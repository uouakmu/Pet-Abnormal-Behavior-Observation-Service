import os
import gc
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import torchvision.transforms as transforms

from PIL import Image, ImageFile
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
from collections import defaultdict
from tqdm import tqdm

ImageFile.LOAD_TRUNCATED_IMAGES = True

# ===============================
# CONFIG
# ===============================

DEVICE = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")

EPOCHS = 50
BATCH_SIZE = 32
NUM_WORKERS = 24
LR = 1e-4
NUM_IMAGES_PER_SAMPLE = 5          # ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•˜ëŠ” ì‚¬ì§„ ìˆ˜
LABEL_SMOOTHING = 0.1

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLASS DEFINITIONS
# ê·œì¹™: dog_ ì ‘ë‘ â†’ dog classes, cat_ ì ‘ë‘ â†’ cat classes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€ 4_Animal_Skin â”€â”€
SKIN_CLASSES = [
    "cat_normal", "cat_ê²°ì ˆ,ì¢…ê´´", "cat_ë†í¬,ì—¬ë“œë¦„",
    "cat_ë¹„ë“¬,ê°ì§ˆ,ìƒí”¼ì„±ì”ê³ ë¦¬", "dog_normal",
    "dog_ê²°ì ˆ,ì¢…ê´´", "dog_ë†í¬,ì—¬ë“œë¦„", "dog_ë¯¸ë€,ê¶¤ì–‘",
    "dog_ë¹„ë“¬,ê°ì§ˆ,ìƒí”¼ì„±ì”ê³ ë¦¬",
]

# â”€â”€ 5_Animal_Eyes â”€â”€
EYES_CLASSES = [
    "cat_normal", "cat_ê°ë§‰ê¶¤ì–‘", "cat_ê°ë§‰ë¶€ê³¨í¸",
    "cat_ê²°ë§‰ì—¼", "cat_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì—¼", "cat_ì•ˆê²€ì—¼",
    "dog_normal", "dog_ê²°ë§‰ì—¼", "dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_ìƒ",
    "dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_í•˜", "dog_ë°±ë‚´ì¥_ë¹„ì„±ìˆ™", "dog_ë°±ë‚´ì¥_ì„±ìˆ™",
    "dog_ë°±ë‚´ì¥_ì´ˆê¸°", "dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_ìƒ", "dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_í•˜",
    "dog_ìƒ‰ì†Œì¹¨ì°©ì„±ê°ë§‰ì—¼", "dog_ì•ˆê²€ë‚´ë°˜ì¦", "dog_ì•ˆê²€ì—¼",
    "dog_ì•ˆê²€ì¢…ì–‘", "dog_ìœ ë£¨ì¦", "dog_í•µê²½í™”"
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ ì‚¬ í´ë˜ìŠ¤ ê·¸ë£¹ ì •ì˜ (Eyes ì „ìš©)
# ë™ì¼ ì§ˆí™˜ ë‚´ ì„¸ë¶„ë¥˜ëŠ” Hierarchical Loss ê°€ì¤‘ì¹˜ë¡œ í˜¼ë™ íŒ¨ë„í‹°ë¥¼ ì¤Œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EYES_SIMILAR_GROUPS = [
    ["dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_ìƒ", "dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_í•˜"],
    ["dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_ìƒ", "dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_í•˜"],
    ["dog_ë°±ë‚´ì¥_ì´ˆê¸°", "dog_ë°±ë‚´ì¥_ë¹„ì„±ìˆ™", "dog_ë°±ë‚´ì¥_ì„±ìˆ™"],
]


# ===============================
# LOSS: Hierarchical-Aware CE
# ===============================
# ê°™ì€ ì§ˆí™˜ ê·¸ë£¹ ë‚´ ì˜¤ë¶„ë¥˜ì— extra_penalty ë¥¼ ê³±í•´
# ëª¨ë¸ì´ ìƒ/í•˜, ì´ˆê¸°/ì„±ìˆ™ êµ¬ë¶„ì„ ë” ì—´ì‹¬íˆ í•™ìŠµí•˜ê²Œ ë§Œë“ ë‹¤.

class HierarchicalWeightedLoss(nn.Module):
    """
    CrossEntropyLoss + Label Smoothing + ìœ ì‚¬ í´ë˜ìŠ¤ í˜¼ë™ í˜ë„í‹°

    Args:
        class_names    : í•™ìŠµ taskì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        similar_groups : ìœ ì‚¬ í´ë˜ìŠ¤ ë¬¶ìŒ [[cls_a, cls_b], ...]
        class_weights  : í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì • weight í…ì„œ
        smoothing      : label smoothing Îµ
        extra_penalty  : ê°™ì€ ê·¸ë£¹ ë‚´ ì˜¤ë¶„ë¥˜ ì‹œ loss ë°°ìœ¨
    """

    def __init__(
        self,
        class_names,
        similar_groups=None,
        class_weights=None,
        smoothing=LABEL_SMOOTHING,
        extra_penalty=1.5,
    ):
        super().__init__()
        self.smoothing      = smoothing
        self.extra_penalty  = extra_penalty
        self.num_classes    = len(class_names)
        self.class_names    = class_names
        self.name_to_idx    = {n: i for i, n in enumerate(class_names)}

        # ìœ ì‚¬ ê·¸ë£¹ â†’ (idx_i, idx_j) pair set
        self.penalty_pairs = set()
        if similar_groups:
            for group in similar_groups:
                idxs = [self.name_to_idx[n] for n in group if n in self.name_to_idx]
                for i in range(len(idxs)):
                    for j in range(i + 1, len(idxs)):
                        self.penalty_pairs.add((idxs[i], idxs[j]))
                        self.penalty_pairs.add((idxs[j], idxs[i]))

        self.register_buffer("weight", class_weights)

    def forward(self, logits, targets):
        """
        logits  : (B, C)
        targets : (B,)  long
        """
        B, C = logits.shape
        device = logits.device

        # â”€â”€ Label Smoothing â”€â”€
        log_prob = F.log_softmax(logits, dim=-1)
        smooth_loss = -log_prob.mean(dim=-1)                              # (B,)
        nll_loss    = F.nll_loss(log_prob, targets, weight=self.weight, reduction="none")  # (B,)
        base_loss   = (1 - self.smoothing) * nll_loss + self.smoothing * smooth_loss  # (B,)

        # â”€â”€ Hierarchical Penalty â”€â”€
        if self.penalty_pairs:
            pred_classes = logits.argmax(dim=-1)          # (B,)
            penalty_mask = torch.ones(B, device=device)
            for b in range(B):
                t = targets[b].item()
                p = pred_classes[b].item()
                if (t, p) in self.penalty_pairs:
                    penalty_mask[b] = self.extra_penalty
            base_loss = base_loss * penalty_mask

        return base_loss.mean()


# ===============================
# CLASS WEIGHT COMPUTATION
# ===============================

def compute_class_weights(sample_counts: dict, class_names: list) -> torch.Tensor:
    """
    Inverse-frequency ë°©ì‹ìœ¼ë¡œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•œë‹¤.
    sample_counts: {class_name: n_samples}
    """
    counts = torch.tensor(
        [sample_counts.get(n, 1) for n in class_names], dtype=torch.float
    )
    weights = 1.0 / counts
    weights = weights / weights.sum() * len(class_names)   # normalize
    return weights


# ===============================
# MODEL DEFINITIONS
# ===============================

class AnomalyMultiBackbone(nn.Module):
    """
    ì´ìƒ ì¦ìƒ Omni ëª¨ë¸
    â”œâ”€â”€ skin_backbone  â†’ Skin ë¶„ë¥˜ (í”¼ë¶€ì§ˆí™˜)
    â””â”€â”€ eyes_backbone  â†’ Eyes ë¶„ë¥˜ (ì•ˆêµ¬ì§ˆí™˜)

    ê° backbone ì€ ResNet50 (ImageNet pretrained) ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°,
    ë§ˆì§€ë§‰ fc ë¥¼ task-specific head ë¡œ êµì²´í•œë‹¤.

    Eyes ì˜ ê²½ìš° ìœ ì‚¬ í´ë˜ìŠ¤ í˜¼ë™ì„ ì¤„ì´ê¸° ìœ„í•´:
      1) Dropout + ë” ê¹Šì€ head
      2) Feature Attention (Channel Squeeze-Excitation)
    ì„ ì¶”ê°€í•œë‹¤.
    """

    def __init__(self, num_skin_classes: int, num_eyes_classes: int):
        super().__init__()

        # â”€â”€ Skin Backbone (ResNet50 pretrained) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        skin_base = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        skin_feat_dim = skin_base.fc.in_features          # 2048
        skin_base.fc = nn.Identity()
        self.skin_backbone = skin_base
        self.skin_head = nn.Sequential(
            nn.Linear(skin_feat_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, num_skin_classes),
        )

        # â”€â”€ Eyes Backbone (ResNet50 pretrained + SE attention) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        eyes_base = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        eyes_feat_dim = eyes_base.fc.in_features
        eyes_base.fc = nn.Identity()
        self.eyes_backbone = eyes_base

        # Squeeze-Excitation: ì±„ë„ ì¤‘ìš”ë„ ì¬ë³´ì • â†’ ë¯¸ì„¸í•œ ë³‘ë³€ êµ¬ë¶„ë ¥ í–¥ìƒ
        self.eyes_se = SqueezeExcitation(eyes_feat_dim, reduction=16)

        # ë” ê¹Šì€ classifier head
        self.eyes_head = nn.Sequential(
            nn.Linear(eyes_feat_dim, 1024),
            nn.BatchNorm1d(1024),
            nn.GELU(),
            nn.Dropout(0.4),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.GELU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_eyes_classes),
        )

    def forward(self, x: torch.Tensor, task: str = "skin") -> torch.Tensor:
        """
        x    : (B, 3, 224, 224)  â€” ë‹¨ì¼ ì´ë¯¸ì§€ ë˜ëŠ” ì•™ìƒë¸” í›„ í‰ê·  logit ìš©
        task : "skin" | "eyes"
        """
        if task == "skin":
            feat = self.skin_backbone(x)
            return self.skin_head(feat)

        elif task == "eyes":
            feat = self.eyes_backbone(x)           # (B, 2048)
            feat = self.eyes_se(feat)              # channel attention
            return self.eyes_head(feat)

        else:
            raise ValueError(f"Unknown task: {task!r}. Choose 'skin' or 'eyes'.")


class SqueezeExcitation(nn.Module):
    """
    1-D Squeeze-Excitation for feature vectors (after global avg pool).
    feat : (B, C)
    """

    def __init__(self, channels: int, reduction: int = 16):
        super().__init__()
        self.se = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid(),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x * self.se(x)


# ===============================
# INFERENCE: 5-Image Ensemble
# ===============================

def predict_anomaly(
    model: AnomalyMultiBackbone,
    images: list,           # list of PIL.Image (5ì¥)
    task: str,              # "skin" | "eyes"
    pet_type: str,          # "dog" | "cat"
    class_names: list,
    device=DEVICE,
) -> dict:
    """
    5ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ í‰ê·  softmax í™•ë¥ ë¡œ ìµœì¢… ì˜ˆì¸¡ì„ ë°˜í™˜í•œë‹¤.

    Returns:
        {
            "predicted_class": str,
            "confidence": float,
            "top3": [(class_name, prob), ...]
        }
    """
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225]),
    ])

    model.eval()
    model.to(device)

    # ë°˜ë ¤ë™ë¬¼ ì¢…ì— ë§ëŠ” class indexë§Œ ì„ íƒ
    valid_idxs = [
        i for i, n in enumerate(class_names) if n.startswith(pet_type + "_")
    ]
    valid_names = [class_names[i] for i in valid_idxs]

    with torch.no_grad():
        probs_accum = torch.zeros(len(class_names), device=device)

        for img in images:
            tensor = transform(img).unsqueeze(0).to(device)   # (1, 3, 224, 224)
            logits = model(tensor, task=task)                  # (1, C)

            # í•´ë‹¹ pet_type ì™¸ class ë§ˆìŠ¤í‚¹ (âˆ’inf â†’ softmax â‰ˆ 0)
            mask = torch.full((len(class_names),), float("-inf"), device=device)
            mask[valid_idxs] = logits[0][valid_idxs]

            probs = F.softmax(mask, dim=-1)
            probs_accum += probs

        probs_accum /= len(images)    # í‰ê·  ì•™ìƒë¸”

    # ìœ íš¨ class ì¤‘ top-k
    valid_probs = [(valid_names[i], probs_accum[valid_idxs[i]].item())
                   for i in range(len(valid_idxs))]
    valid_probs.sort(key=lambda x: x[1], reverse=True)

    return {
        "predicted_class": valid_probs[0][0],
        "confidence":      valid_probs[0][1],
        "top3":            valid_probs[:3],
    }


# ===============================
# DATASETS
# ===============================

class AnomalyDataset(Dataset):
    """
    ë°ì´í„°ì…‹ êµ¬ì¡°:
        root_dir/
            dog_ê²°ë§‰ì—¼/  img001.jpg ...
            cat_normal/  img001.jpg ...
            ...

    task      : "skin" | "eyes"
    pet_type  : "dog" | "cat" | "all"
    """

    TRANSFORM = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225]),
    ])

    TRANSFORM_VAL = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225]),
    ])

    def __init__(
        self,
        root_dir: str,
        class_names: list,
        task: str,
        is_train: bool = True,
    ):
        self.class_names = class_names
        self.task        = task
        self.transform   = self.TRANSFORM if is_train else self.TRANSFORM_VAL
        self.name_to_idx = {n: i for i, n in enumerate(class_names)}

        self.samples = []   # [(img_path, label_idx), ...]

        for class_name in class_names:
            class_dir = os.path.join(root_dir, class_name)
            if not os.path.isdir(class_dir):
                continue
            label_idx = self.name_to_idx[class_name]
            for fname in os.listdir(class_dir):
                if fname.lower().endswith((".jpg", ".jpeg", ".png")):
                    self.samples.append((os.path.join(class_dir, fname), label_idx))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        img = Image.open(img_path).convert("RGB")
        return self.transform(img), label

    @staticmethod
    def get_sample_counts(root_dir: str, class_names: list) -> dict:
        counts = {}
        for cn in class_names:
            d = os.path.join(root_dir, cn)
            if os.path.isdir(d):
                counts[cn] = len([
                    f for f in os.listdir(d)
                    if f.lower().endswith((".jpg", ".jpeg", ".png"))
                ])
            else:
                counts[cn] = 1
        return counts


# ===============================
# TRAIN FUNCTION
# ===============================

def train(
    skin_root: str = "files/4_Animal_Skin",
    eyes_root: str = "files/5_Animal_Eyes",
):
    # â”€â”€ í´ë˜ìŠ¤ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    skin_classes = SKIN_CLASSES
    eyes_classes = EYES_CLASSES

    num_skin  = len(skin_classes)
    num_eyes  = len(eyes_classes)

    # â”€â”€ ëª¨ë¸ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    model = AnomalyMultiBackbone(num_skin, num_eyes)

    # â”€â”€ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ë¶ˆê· í˜• ë³´ì •) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    skin_counts  = AnomalyDataset.get_sample_counts(skin_root, skin_classes)
    eyes_counts  = AnomalyDataset.get_sample_counts(eyes_root, eyes_classes)

    skin_weights = compute_class_weights(skin_counts, skin_classes).to(DEVICE)
    eyes_weights = compute_class_weights(eyes_counts, eyes_classes).to(DEVICE)

    # â”€â”€ Loss â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    skin_criterion = HierarchicalWeightedLoss(
        class_names   = skin_classes,
        class_weights = skin_weights,
        smoothing     = LABEL_SMOOTHING,
    )
    eyes_criterion = HierarchicalWeightedLoss(
        class_names    = eyes_classes,
        similar_groups = EYES_SIMILAR_GROUPS,
        class_weights  = eyes_weights,
        smoothing      = LABEL_SMOOTHING,
        extra_penalty  = 1.5,
    )

    # â”€â”€ Optimizer & Scheduler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)

    scaler = GradScaler()

    # â”€â”€ í•™ìŠµ ê¸°ë¡ & Best ì¶”ì  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    history      = []   # {epoch, skin_loss, skin_acc, eyes_loss, eyes_acc, avg_acc}
    best_avg_acc = 0.0
    best_epoch   = 0

    # â”€â”€ Training Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for epoch in range(EPOCHS):
        print(f"\n========= Epoch {epoch + 1}/{EPOCHS} =========\n")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 1ï¸âƒ£  Skin Training
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("[1/2] Skin Training")
        model.to(DEVICE)
        model.train()

        skin_dataset = AnomalyDataset(skin_root, skin_classes, task="skin", is_train=True)
        skin_loader  = DataLoader(
            skin_dataset,
            batch_size  = BATCH_SIZE,
            shuffle     = True,
            num_workers = NUM_WORKERS,
            pin_memory  = True,
        )

        skin_loss_sum, skin_correct, skin_total = 0.0, 0, 0

        skin_pbar = tqdm(skin_loader, desc=f"  [Skin ] Epoch {epoch+1:02d}/{EPOCHS}", ncols=110, leave=True)
        for images, labels in skin_pbar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()

            with autocast():
                outputs = model(images, task="skin")
                loss    = skin_criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            skin_loss_sum += loss.item() * images.size(0)
            skin_correct  += (outputs.argmax(1) == labels).sum().item()
            skin_total    += images.size(0)

            skin_pbar.set_postfix(
                loss=f"{skin_loss_sum / skin_total:.4f}",
                acc=f"{100 * skin_correct / skin_total:.2f}%"
            )

        del skin_loader, skin_dataset
        gc.collect()
        torch.cuda.empty_cache()

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 2ï¸âƒ£  Eyes Training
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("[2/2] Eyes Training")

        eyes_dataset = AnomalyDataset(eyes_root, eyes_classes, task="eyes", is_train=True)
        eyes_loader  = DataLoader(
            eyes_dataset,
            batch_size  = BATCH_SIZE,
            shuffle     = True,
            num_workers = NUM_WORKERS,
            pin_memory  = True,
        )

        eyes_loss_sum, eyes_correct, eyes_total = 0.0, 0, 0

        eyes_pbar = tqdm(eyes_loader, desc=f"  [Eyes ] Epoch {epoch+1:02d}/{EPOCHS}", ncols=110, leave=True)
        for images, labels in eyes_pbar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()

            with autocast():
                outputs = model(images, task="eyes")
                loss    = eyes_criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            eyes_loss_sum += loss.item() * images.size(0)
            eyes_correct  += (outputs.argmax(1) == labels).sum().item()
            eyes_total    += images.size(0)

            eyes_pbar.set_postfix(
                loss=f"{eyes_loss_sum / eyes_total:.4f}",
                acc=f"{100 * eyes_correct / eyes_total:.2f}%"
            )

        del eyes_loader, eyes_dataset
        gc.collect()
        torch.cuda.empty_cache()

        # â”€â”€ LR Scheduler Step â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        scheduler.step()

        # â”€â”€ History ê¸°ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        skin_epoch_loss = skin_loss_sum / skin_total
        skin_epoch_acc  = skin_correct  / skin_total
        eyes_epoch_loss = eyes_loss_sum / eyes_total
        eyes_epoch_acc  = eyes_correct  / eyes_total
        avg_acc         = (skin_epoch_acc + eyes_epoch_acc) / 2

        history.append({
            'epoch'     : epoch + 1,
            'skin_loss' : skin_epoch_loss,
            'skin_acc'  : skin_epoch_acc,
            'eyes_loss' : eyes_epoch_loss,
            'eyes_acc'  : eyes_epoch_acc,
            'avg_acc'   : avg_acc,
        })

        print(f"  Skin | Loss: {skin_epoch_loss:.4f} | Acc: {skin_epoch_acc*100:.2f}%")
        print(f"  Eyes | Loss: {eyes_epoch_loss:.4f} | Acc: {eyes_epoch_acc*100:.2f}%")
        print(f"  Avg Acc: {avg_acc*100:.2f}%")

        # â”€â”€ Best Model ì €ì¥ (avg acc ê¸°ì¤€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if avg_acc > best_avg_acc:
            best_avg_acc = avg_acc
            best_epoch   = epoch + 1
            torch.save(
                {
                    "model"           : model.state_dict(),
                    "epoch"           : epoch + 1,
                    "best_avg_acc"    : best_avg_acc,
                    "skin_classes"    : SKIN_CLASSES,
                    "eyes_classes"    : EYES_CLASSES,
                    "history"         : history,
                },
                "pet_abnormal_omni_best.pth",
            )
            print(f"  ğŸ’¾ Saved best model! (Epoch {best_epoch} | Avg Acc: {best_avg_acc*100:.2f}%)")


    print(f"\nğŸ† Training Finished. Best Epoch: {best_epoch} | Best Avg Acc: {best_avg_acc*100:.2f}%")

    # â”€â”€ í•™ìŠµ ê³¡ì„  ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("â†’3ï¸âƒ£  Generating training history plot...")
    import matplotlib.pyplot as plt

    epochs_x     = [h['epoch']     for h in history]
    skin_losses  = [h['skin_loss'] for h in history]
    eyes_losses  = [h['eyes_loss'] for h in history]
    skin_accs    = [h['skin_acc']  for h in history]
    eyes_accs    = [h['eyes_acc']  for h in history]
    avg_accs     = [h['avg_acc']   for h in history]

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # â”€ Loss â”€
    axes[0].plot(epochs_x, skin_losses, 'b-',  linewidth=2, label='Skin Loss')
    axes[0].plot(epochs_x, eyes_losses, 'r-',  linewidth=2, label='Eyes Loss')
    axes[0].axvline(best_epoch, color='gray', linestyle='--', alpha=0.6, label=f'Best Epoch {best_epoch}')
    axes[0].set_title('Training Loss');  axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')
    axes[0].legend(); axes[0].grid(True, alpha=0.3)

    # â”€ Accuracy â”€
    axes[1].plot(epochs_x, skin_accs, 'b-',  linewidth=2, label='Skin Acc')
    axes[1].plot(epochs_x, eyes_accs, 'r-',  linewidth=2, label='Eyes Acc')
    axes[1].axvline(best_epoch, color='gray', linestyle='--', alpha=0.6, label=f'Best Epoch {best_epoch}')
    axes[1].set_title('Training Accuracy'); axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Accuracy')
    axes[1].set_ylim(0, 1); axes[1].legend(); axes[1].grid(True, alpha=0.3)

    # â”€ Avg Accuracy â”€
    axes[2].plot(epochs_x, avg_accs, 'g-', linewidth=2, label='Avg Acc')
    axes[2].axvline(best_epoch, color='gray', linestyle='--', alpha=0.6, label=f'Best Epoch {best_epoch}')
    axes[2].axhline(best_avg_acc, color='green', linestyle=':', alpha=0.6, label=f'Best Acc {best_avg_acc*100:.1f}%')
    axes[2].set_title('Average Accuracy');  axes[2].set_xlabel('Epoch'); axes[2].set_ylabel('Accuracy')
    axes[2].set_ylim(0, 1); axes[2].legend(); axes[2].grid(True, alpha=0.3)

    plt.suptitle('Anomaly Model Training History', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig('anomaly_training_history.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("  âœ… Saved: pet_abnormal_omni.png")


# ===============================
# ENTRY POINT
# ===============================

if __name__ == "__main__":
    train()