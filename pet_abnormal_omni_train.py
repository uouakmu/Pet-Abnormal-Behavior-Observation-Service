import os
import gc
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

from PIL import Image, ImageFile
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
from collections import defaultdict
from tqdm import tqdm

ImageFile.LOAD_TRUNCATED_IMAGES = True

# ===============================
# CONFIG
# ===============================

SEED = 42
random.seed(SEED)
torch.manual_seed(SEED)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

EPOCHS                = 50
BATCH_SIZE            = 32
NUM_WORKERS           = 24
LR                    = 1e-4
NUM_IMAGES_PER_SAMPLE = 5      # ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•˜ëŠ” ì‚¬ì§„ ìˆ˜
LABEL_SMOOTHING       = 0.1

# train 80% / val 10% / test 10%
VAL_RATIO  = 0.1
TEST_RATIO = 0.1

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLASS DEFINITIONS
# ê·œì¹™: dog_ ì ‘ë‘ â†’ dog classes, cat_ ì ‘ë‘ â†’ cat classes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€ 4_Animal_Skin â”€â”€
SKIN_CLASSES = [
    "cat_normal", "cat_ê²°ì ˆ,ì¢…ê´´", "cat_ë†í¬,ì—¬ë“œë¦„",
    "cat_ë¹„ë“¬,ê°ì§ˆ,ìƒí”¼ì„±ì”ê³ ë¦¬", "dog_normal",
    "dog_ê²°ì ˆ,ì¢…ê´´", "dog_ë†í¬,ì—¬ë“œë¦„", "dog_ë¯¸ë€,ê¶¤ì–‘",
    "dog_ë¹„ë“¬,ê°ì§ˆ,ìƒí”¼ì„±ì”ê³ ë¦¬",
]

# â”€â”€ 5_Animal_Eyes â”€â”€
EYES_CLASSES = [
    "cat_normal", "cat_ê°ë§‰ê¶¤ì–‘", "cat_ê°ë§‰ë¶€ê³¨í¸",
    "cat_ê²°ë§‰ì—¼", "cat_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì—¼", "cat_ì•ˆê²€ì—¼",
    "dog_normal", "dog_ê²°ë§‰ì—¼", "dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_ìƒ",
    "dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_í•˜", "dog_ë°±ë‚´ì¥_ë¹„ì„±ìˆ™", "dog_ë°±ë‚´ì¥_ì„±ìˆ™",
    "dog_ë°±ë‚´ì¥_ì´ˆê¸°", "dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_ìƒ", "dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_í•˜",
    "dog_ìƒ‰ì†Œì¹¨ì°©ì„±ê°ë§‰ì—¼", "dog_ì•ˆê²€ë‚´ë°˜ì¦", "dog_ì•ˆê²€ì—¼",
    "dog_ì•ˆê²€ì¢…ì–‘", "dog_ìœ ë£¨ì¦", "dog_í•µê²½í™”",
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ ì‚¬ í´ë˜ìŠ¤ ê·¸ë£¹ ì •ì˜ (Eyes ì „ìš©)
# ë™ì¼ ì§ˆí™˜ ë‚´ ì„¸ë¶„ë¥˜ëŠ” Hierarchical Loss ê°€ì¤‘ì¹˜ë¡œ í˜¼ë™ íŒ¨ë„í‹°ë¥¼ ì¤Œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EYES_SIMILAR_GROUPS = [
    ["dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_ìƒ", "dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_í•˜"],
    ["dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_ìƒ",   "dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜_í•˜"],
    ["dog_ë°±ë‚´ì¥_ì´ˆê¸°", "dog_ë°±ë‚´ì¥_ë¹„ì„±ìˆ™", "dog_ë°±ë‚´ì¥_ì„±ìˆ™"],
]


# ===============================
# LOSS: Hierarchical-Aware CE
# ===============================

class HierarchicalWeightedLoss(nn.Module):
    """
    CrossEntropyLoss + Label Smoothing + ìœ ì‚¬ í´ë˜ìŠ¤ í˜¼ë™ í˜ë„í‹°

    Args:
        class_names    : í•™ìŠµ taskì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        similar_groups : ìœ ì‚¬ í´ë˜ìŠ¤ ë¬¶ìŒ [[cls_a, cls_b], ...]
        class_weights  : í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì • weight í…ì„œ
        smoothing      : label smoothing Îµ
        extra_penalty  : ê°™ì€ ê·¸ë£¹ ë‚´ ì˜¤ë¶„ë¥˜ ì‹œ loss ë°°ìœ¨
    """

    def __init__(
        self,
        class_names,
        similar_groups=None,
        class_weights=None,
        smoothing=LABEL_SMOOTHING,
        extra_penalty=1.5,
    ):
        super().__init__()
        self.smoothing     = smoothing
        self.extra_penalty = extra_penalty
        self.num_classes   = len(class_names)
        self.class_names   = class_names
        self.name_to_idx   = {n: i for i, n in enumerate(class_names)}

        # ìœ ì‚¬ ê·¸ë£¹ â†’ (idx_i, idx_j) pair set
        self.penalty_pairs = set()
        if similar_groups:
            for group in similar_groups:
                idxs = [self.name_to_idx[n] for n in group if n in self.name_to_idx]
                for i in range(len(idxs)):
                    for j in range(i + 1, len(idxs)):
                        self.penalty_pairs.add((idxs[i], idxs[j]))
                        self.penalty_pairs.add((idxs[j], idxs[i]))

        self.register_buffer("weight", class_weights)

    def forward(self, logits, targets):
        B, C   = logits.shape
        device = logits.device

        # â”€â”€ Label Smoothing â”€â”€
        log_prob    = F.log_softmax(logits, dim=-1)
        smooth_loss = -log_prob.mean(dim=-1)                                               # (B,)
        nll_loss    = F.nll_loss(log_prob, targets, weight=self.weight, reduction="none")  # (B,)
        base_loss   = (1 - self.smoothing) * nll_loss + self.smoothing * smooth_loss       # (B,)

        # â”€â”€ Hierarchical Penalty â”€â”€
        if self.penalty_pairs:
            pred_classes = logits.argmax(dim=-1)
            penalty_mask = torch.ones(B, device=device)
            for b in range(B):
                t = targets[b].item()
                p = pred_classes[b].item()
                if (t, p) in self.penalty_pairs:
                    penalty_mask[b] = self.extra_penalty
            base_loss = base_loss * penalty_mask

        return base_loss.mean()


# ===============================
# CLASS WEIGHT COMPUTATION
# ===============================

def compute_class_weights(sample_counts: dict, class_names: list) -> torch.Tensor:
    """Inverse-frequency ë°©ì‹ìœ¼ë¡œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•œë‹¤."""
    counts  = torch.tensor([sample_counts.get(n, 1) for n in class_names], dtype=torch.float)
    weights = 1.0 / counts
    weights = weights / weights.sum() * len(class_names)   # normalize
    return weights


# ===============================
# MODEL DEFINITIONS
# ===============================

class AnomalyMultiBackbone(nn.Module):
    """
    ì´ìƒ ì¦ìƒ Omni ëª¨ë¸
    â”œâ”€â”€ skin_backbone  â†’ Skin ë¶„ë¥˜ (í”¼ë¶€ì§ˆí™˜)
    â””â”€â”€ eyes_backbone  â†’ Eyes ë¶„ë¥˜ (ì•ˆêµ¬ì§ˆí™˜)
    """

    def __init__(self, num_skin_classes: int, num_eyes_classes: int):
        super().__init__()

        # â”€â”€ Skin Backbone (ResNet50 pretrained) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        skin_base          = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        skin_feat_dim      = skin_base.fc.in_features   # 2048
        skin_base.fc       = nn.Identity()
        self.skin_backbone = skin_base
        self.skin_head = nn.Sequential(
            nn.Linear(skin_feat_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, num_skin_classes),
        )

        # â”€â”€ Eyes Backbone (ResNet50 pretrained + SE attention) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        eyes_base          = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        eyes_feat_dim      = eyes_base.fc.in_features
        eyes_base.fc       = nn.Identity()
        self.eyes_backbone = eyes_base
        self.eyes_se       = SqueezeExcitation(eyes_feat_dim, reduction=16)
        self.eyes_head = nn.Sequential(
            nn.Linear(eyes_feat_dim, 1024),
            nn.BatchNorm1d(1024),
            nn.GELU(),
            nn.Dropout(0.4),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.GELU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_eyes_classes),
        )

    def forward(self, x: torch.Tensor, task: str = "skin") -> torch.Tensor:
        if task == "skin":
            return self.skin_head(self.skin_backbone(x))
        elif task == "eyes":
            feat = self.eyes_backbone(x)
            feat = self.eyes_se(feat)
            return self.eyes_head(feat)
        else:
            raise ValueError(f"Unknown task: {task!r}. Choose 'skin' or 'eyes'.")


class SqueezeExcitation(nn.Module):
    """1-D Squeeze-Excitation for feature vectors (after global avg pool)."""

    def __init__(self, channels: int, reduction: int = 16):
        super().__init__()
        self.se = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid(),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x * self.se(x)


# ===============================
# INFERENCE: 5-Image Ensemble
# ===============================

def predict_anomaly(
    model: AnomalyMultiBackbone,
    images: list,
    task: str,
    pet_type: str,
    class_names: list,
    device=DEVICE,
) -> dict:
    """
    5ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ í‰ê·  softmax í™•ë¥ ë¡œ ìµœì¢… ì˜ˆì¸¡ì„ ë°˜í™˜í•œë‹¤.

    Returns:
        {"predicted_class": str, "confidence": float, "top3": [(class_name, prob), ...]}
    """
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])

    model.eval()
    model.to(device)

    valid_idxs  = [i for i, n in enumerate(class_names) if n.startswith(pet_type + "_")]
    valid_names = [class_names[i] for i in valid_idxs]

    with torch.no_grad():
        probs_accum = torch.zeros(len(class_names), device=device)
        for img in images:
            tensor = transform(img).unsqueeze(0).to(device)
            logits = model(tensor, task=task)
            mask   = torch.full((len(class_names),), float("-inf"), device=device)
            mask[valid_idxs] = logits[0][valid_idxs]
            probs_accum += F.softmax(mask, dim=-1)
        probs_accum /= len(images)

    valid_probs = [(valid_names[i], probs_accum[valid_idxs[i]].item()) for i in range(len(valid_idxs))]
    valid_probs.sort(key=lambda x: x[1], reverse=True)

    return {
        "predicted_class": valid_probs[0][0],
        "confidence":      valid_probs[0][1],
        "top3":            valid_probs[:3],
    }


# ===============================
# DATA SPLIT UTILITY
# ===============================

def collect_and_split(
    root_dir: str,
    class_names: list,
    val_ratio: float  = VAL_RATIO,
    test_ratio: float = TEST_RATIO,
    seed: int         = SEED,
):
    """
    root_dir í•˜ìœ„ class ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ê³ 
    í´ë˜ìŠ¤ë³„ stratified splitìœ¼ë¡œ train / val / test ë¥¼ ë°˜í™˜í•œë‹¤.

    [ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€]
    - íŒŒì¼ ê²½ë¡œ ì¤‘ë³µ ì œê±° (seen set)
    - í´ë˜ìŠ¤ë³„ë¡œ ë…ë¦½ shuffle í›„ ë¹„ìœ¨ ë¶„ë¦¬
      â†’ train / val / test ê°„ ë™ì¼ íŒŒì¼ ì ˆëŒ€ ë¯¸í¬í•¨

    Returns:
        train_samples, val_samples, test_samples
        ê° ì›ì†Œ: (img_path: str, label_idx: int)
    """
    rng         = random.Random(seed)
    name_to_idx = {n: i for i, n in enumerate(class_names)}
    class_files = defaultdict(list)
    seen_paths  = set()

    for class_name in class_names:
        class_dir = os.path.join(root_dir, class_name)
        if not os.path.isdir(class_dir):
            continue
        label_idx = name_to_idx[class_name]
        for fname in os.listdir(class_dir):
            if not fname.lower().endswith((".jpg", ".jpeg", ".png")):
                continue
            fpath = os.path.join(class_dir, fname)
            if fpath in seen_paths:      # ì¤‘ë³µ íŒŒì¼ ì œê±°
                continue
            seen_paths.add(fpath)
            class_files[label_idx].append(fpath)

    train_samples, val_samples, test_samples = [], [], []

    for label_idx, paths in class_files.items():
        rng.shuffle(paths)
        n       = len(paths)
        n_val   = max(1, int(n * val_ratio))
        n_test  = max(1, int(n * test_ratio))
        n_train = n - n_val - n_test

        # ìƒ˜í”Œ ìˆ˜ê°€ ë„ˆë¬´ ì ì€ í´ë˜ìŠ¤ ê²½ê³ 
        if n_train <= 0:
            print(f"  âš ï¸  í´ë˜ìŠ¤ idx={label_idx}: ìƒ˜í”Œ ìˆ˜({n})ê°€ ë„ˆë¬´ ì ì–´ trainì´ 0ê°œì…ë‹ˆë‹¤.")
            n_train, n_val, n_test = n, 0, 0

        train_samples.extend([(p, label_idx) for p in paths[:n_train]])
        val_samples.extend(  [(p, label_idx) for p in paths[n_train:n_train + n_val]])
        test_samples.extend( [(p, label_idx) for p in paths[n_train + n_val:]])

    print(f"  â†’ train: {len(train_samples)} | val: {len(val_samples)} | test: {len(test_samples)}")
    return train_samples, val_samples, test_samples


def count_samples_from_split(samples: list, class_names: list) -> dict:
    """splitëœ samplesì—ì„œ class_nameë³„ ê°œìˆ˜ë¥¼ ë°˜í™˜ (class_weight ê³„ì‚°ìš©)."""
    idx_to_name = {i: n for i, n in enumerate(class_names)}
    counts      = defaultdict(int)
    for _, label_idx in samples:
        counts[idx_to_name[label_idx]] += 1
    return dict(counts)


# ===============================
# DATASETS
# ===============================

class AnomalyDataset(Dataset):
    """
    collect_and_split() ê²°ê³¼ë¥¼ ë°›ì•„ Datasetìœ¼ë¡œ ë˜í•‘í•œë‹¤.

    samples  : [(img_path, label_idx), ...]
    is_train : True  â†’ augmentation ì ìš©
               False â†’ resize only (val / test)
    """

    TRANSFORM_TRAIN = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])

    TRANSFORM_VAL = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])

    def __init__(self, samples: list, is_train: bool = True):
        self.samples   = samples
        self.transform = self.TRANSFORM_TRAIN if is_train else self.TRANSFORM_VAL

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        img = Image.open(img_path).convert("RGB")
        return self.transform(img), label


# ===============================
# TRAIN FUNCTION
# ===============================

def train(
    skin_root: str = "files/4_Animal_Skin",
    eyes_root: str = "files/5_Animal_Eyes",
):
    print(f"ğŸ¯ Device: {DEVICE}")

    skin_classes = SKIN_CLASSES
    eyes_classes = EYES_CLASSES

    # â”€â”€ Train / Val / Test Split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í´ë˜ìŠ¤ë³„ stratified split â†’ ëˆ„ìˆ˜ ì—†ìŒ
    print("\nğŸ“¦ Splitting Skin dataset...")
    skin_train_samples, skin_val_samples, _ = collect_and_split(skin_root, skin_classes)

    print("\nğŸ“¦ Splitting Eyes dataset...")
    eyes_train_samples, eyes_val_samples, _ = collect_and_split(eyes_root, eyes_classes)

    # â”€â”€ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: train split ê¸°ì¤€ìœ¼ë¡œë§Œ ê³„ì‚° (val/test ì •ë³´ ëˆ„ìˆ˜ ë°©ì§€) â”€â”€
    skin_train_counts = count_samples_from_split(skin_train_samples, skin_classes)
    eyes_train_counts = count_samples_from_split(eyes_train_samples, eyes_classes)

    skin_weights = compute_class_weights(skin_train_counts, skin_classes).to(DEVICE)
    eyes_weights = compute_class_weights(eyes_train_counts, eyes_classes).to(DEVICE)

    # â”€â”€ Loss â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    skin_criterion = HierarchicalWeightedLoss(
        class_names   = skin_classes,
        class_weights = skin_weights,
        smoothing     = LABEL_SMOOTHING,
    )
    eyes_criterion = HierarchicalWeightedLoss(
        class_names    = eyes_classes,
        similar_groups = EYES_SIMILAR_GROUPS,
        class_weights  = eyes_weights,
        smoothing      = LABEL_SMOOTHING,
        extra_penalty  = 1.5,
    )

    # â”€â”€ ëª¨ë¸ / Optimizer / Scheduler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    model     = AnomalyMultiBackbone(len(skin_classes), len(eyes_classes)).to(DEVICE)
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    scaler    = GradScaler()

    # â”€â”€ í•™ìŠµ ê¸°ë¡ & Best ì¶”ì  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    history      = []
    best_avg_acc = 0.0
    best_epoch   = 0

    # â”€â”€ Training Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for epoch in range(EPOCHS):
        print(f"\n{'='*55}")
        print(f"Epoch {epoch + 1}/{EPOCHS}")
        print(f"{'='*55}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 1. Skin Training
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("\n[Train 1/2] Skin")
        model.train()

        skin_train_ds     = AnomalyDataset(skin_train_samples, is_train=True)
        skin_train_loader = DataLoader(
            skin_train_ds, batch_size=BATCH_SIZE, shuffle=True,
            num_workers=NUM_WORKERS, pin_memory=True,
            persistent_workers=(NUM_WORKERS > 0), prefetch_factor=4,
        )

        skin_loss_sum, skin_correct, skin_total = 0.0, 0, 0
        for images, labels in tqdm(skin_train_loader, desc=f"  Skin Train Ep{epoch+1:02d}", ncols=110, leave=True):
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            with autocast():
                outputs = model(images, task="skin")
                loss    = skin_criterion(outputs, labels)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            skin_loss_sum += loss.item() * images.size(0)
            skin_correct  += (outputs.argmax(1) == labels).sum().item()
            skin_total    += images.size(0)

        skin_train_loss = skin_loss_sum / skin_total
        skin_train_acc  = skin_correct  / skin_total

        del skin_train_ds, skin_train_loader
        gc.collect(); torch.cuda.empty_cache()

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 2. Eyes Training
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("\n[Train 2/2] Eyes")

        eyes_train_ds     = AnomalyDataset(eyes_train_samples, is_train=True)
        eyes_train_loader = DataLoader(
            eyes_train_ds, batch_size=BATCH_SIZE, shuffle=True,
            num_workers=NUM_WORKERS, pin_memory=True,
            persistent_workers=(NUM_WORKERS > 0), prefetch_factor=4,
        )

        eyes_loss_sum, eyes_correct, eyes_total = 0.0, 0, 0
        for images, labels in tqdm(eyes_train_loader, desc=f"  Eyes Train Ep{epoch+1:02d}", ncols=110, leave=True):
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            with autocast():
                outputs = model(images, task="eyes")
                loss    = eyes_criterion(outputs, labels)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            eyes_loss_sum += loss.item() * images.size(0)
            eyes_correct  += (outputs.argmax(1) == labels).sum().item()
            eyes_total    += images.size(0)

        eyes_train_loss = eyes_loss_sum / eyes_total
        eyes_train_acc  = eyes_correct  / eyes_total

        del eyes_train_ds, eyes_train_loader
        gc.collect(); torch.cuda.empty_cache()

        # LR Scheduler Step
        scheduler.step()

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 3. Validation  â† [ìˆ˜ì •] ì¶”ê°€: val acc ê¸°ì¤€ìœ¼ë¡œ best model ì €ì¥
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("\n[Val] Skin & Eyes")
        model.eval()

        # Skin Val
        skin_val_ds     = AnomalyDataset(skin_val_samples, is_train=False)
        skin_val_loader = DataLoader(
            skin_val_ds, batch_size=BATCH_SIZE, shuffle=False,
            num_workers=NUM_WORKERS // 2, pin_memory=True,
            persistent_workers=(NUM_WORKERS // 2 > 0), prefetch_factor=4,
        )

        skin_val_loss_sum, skin_val_correct, skin_val_total = 0.0, 0, 0
        with torch.no_grad():
            for images, labels in tqdm(skin_val_loader, desc="  Skin Val  ", ncols=110, leave=False):
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                with autocast():
                    outputs = model(images, task="skin")
                    loss    = skin_criterion(outputs, labels)
                skin_val_loss_sum += loss.item() * images.size(0)
                skin_val_correct  += (outputs.argmax(1) == labels).sum().item()
                skin_val_total    += images.size(0)

        skin_val_loss = skin_val_loss_sum / skin_val_total
        skin_val_acc  = skin_val_correct  / skin_val_total

        del skin_val_ds, skin_val_loader
        gc.collect(); torch.cuda.empty_cache()

        # Eyes Val
        eyes_val_ds     = AnomalyDataset(eyes_val_samples, is_train=False)
        eyes_val_loader = DataLoader(
            eyes_val_ds, batch_size=BATCH_SIZE, shuffle=False,
            num_workers=NUM_WORKERS // 2, pin_memory=True,
            persistent_workers=(NUM_WORKERS // 2 > 0), prefetch_factor=4,
        )

        eyes_val_loss_sum, eyes_val_correct, eyes_val_total = 0.0, 0, 0
        with torch.no_grad():
            for images, labels in tqdm(eyes_val_loader, desc="  Eyes Val  ", ncols=110, leave=False):
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                with autocast():
                    outputs = model(images, task="eyes")
                    loss    = eyes_criterion(outputs, labels)
                eyes_val_loss_sum += loss.item() * images.size(0)
                eyes_val_correct  += (outputs.argmax(1) == labels).sum().item()
                eyes_val_total    += images.size(0)

        eyes_val_loss = eyes_val_loss_sum / eyes_val_total
        eyes_val_acc  = eyes_val_correct  / eyes_val_total

        del eyes_val_ds, eyes_val_loader
        gc.collect(); torch.cuda.empty_cache()

        # â”€â”€ ê²°ê³¼ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        avg_val_acc = (skin_val_acc + eyes_val_acc) / 2

        print(f"\nğŸ“Š Epoch {epoch+1} Results:")
        print(f"  Skin â”‚ Train  Loss: {skin_train_loss:.4f}  Acc: {skin_train_acc*100:.2f}%"
              f"  â”‚  Val Loss: {skin_val_loss:.4f}  Acc: {skin_val_acc*100:.2f}%")
        print(f"  Eyes â”‚ Train  Loss: {eyes_train_loss:.4f}  Acc: {eyes_train_acc*100:.2f}%"
              f"  â”‚  Val Loss: {eyes_val_loss:.4f}  Acc: {eyes_val_acc*100:.2f}%")
        print(f"  Avg Val Acc: {avg_val_acc*100:.2f}%")

        # â”€â”€ History ê¸°ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        history.append({
            'epoch'          : epoch + 1,
            'skin_train_loss': skin_train_loss,
            'skin_train_acc' : skin_train_acc,
            'skin_val_loss'  : skin_val_loss,
            'skin_val_acc'   : skin_val_acc,
            'eyes_train_loss': eyes_train_loss,
            'eyes_train_acc' : eyes_train_acc,
            'eyes_val_loss'  : eyes_val_loss,
            'eyes_val_acc'   : eyes_val_acc,
            'avg_val_acc'    : avg_val_acc,
        })

        # â”€â”€ Best Model ì €ì¥: val acc ê¸°ì¤€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # [ìˆ˜ì •] ê¸°ì¡´: train acc ê¸°ì¤€ â†’ ê³¼ì í•© ëª¨ë¸ì´ ì €ì¥ë  ìœ„í—˜
        #        ë³€ê²½: val acc ê¸°ì¤€  â†’ ì‹¤ì œ ì¼ë°˜í™” ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì €ì¥
        if avg_val_acc > best_avg_acc:
            best_avg_acc = avg_val_acc
            best_epoch   = epoch + 1
            torch.save(
                {
                    "model"        : model.state_dict(),
                    "epoch"        : epoch + 1,
                    "best_avg_acc" : best_avg_acc,
                    "skin_classes" : SKIN_CLASSES,
                    "eyes_classes" : EYES_CLASSES,
                    "history"      : history,
                },
                "pet_abnormal_omni_best.pth",
            )
            print(f"  ğŸ’¾ Saved best model! (Epoch {best_epoch} | Val Avg Acc: {best_avg_acc*100:.2f}%)")

    print(f"\nğŸ† Training Finished.")
    print(f"   Best Epoch: {best_epoch} | Best Val Avg Acc: {best_avg_acc*100:.2f}%")

    # â”€â”€ í•™ìŠµ ê³¡ì„  ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“ˆ Generating training history plot...")

    epochs_x        = [h['epoch']           for h in history]
    skin_tr_losses  = [h['skin_train_loss']  for h in history]
    skin_val_losses = [h['skin_val_loss']    for h in history]
    eyes_tr_losses  = [h['eyes_train_loss']  for h in history]
    eyes_val_losses = [h['eyes_val_loss']    for h in history]
    skin_tr_accs    = [h['skin_train_acc']   for h in history]
    skin_val_accs   = [h['skin_val_acc']     for h in history]
    eyes_tr_accs    = [h['eyes_train_acc']   for h in history]
    eyes_val_accs   = [h['eyes_val_acc']     for h in history]
    avg_val_accs    = [h['avg_val_acc']      for h in history]

    fig, axes = plt.subplots(1, 3, figsize=(20, 5))

    # â”€ Loss â”€
    axes[0].plot(epochs_x, skin_tr_losses,  'b-',  linewidth=2, label='Skin Train Loss')
    axes[0].plot(epochs_x, skin_val_losses, 'b--', linewidth=2, label='Skin Val Loss')
    axes[0].plot(epochs_x, eyes_tr_losses,  'r-',  linewidth=2, label='Eyes Train Loss')
    axes[0].plot(epochs_x, eyes_val_losses, 'r--', linewidth=2, label='Eyes Val Loss')
    axes[0].axvline(best_epoch, color='gray', linestyle=':', alpha=0.7, label=f'Best Epoch {best_epoch}')
    axes[0].set_title('Loss');    axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')
    axes[0].legend();             axes[0].grid(True, alpha=0.3)

    # â”€ Accuracy â”€
    axes[1].plot(epochs_x, skin_tr_accs,  'b-',  linewidth=2, label='Skin Train Acc')
    axes[1].plot(epochs_x, skin_val_accs, 'b--', linewidth=2, label='Skin Val Acc')
    axes[1].plot(epochs_x, eyes_tr_accs,  'r-',  linewidth=2, label='Eyes Train Acc')
    axes[1].plot(epochs_x, eyes_val_accs, 'r--', linewidth=2, label='Eyes Val Acc')
    axes[1].axvline(best_epoch, color='gray', linestyle=':', alpha=0.7, label=f'Best Epoch {best_epoch}')
    axes[1].set_title('Accuracy'); axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Accuracy')
    axes[1].set_ylim(0, 1);        axes[1].legend();            axes[1].grid(True, alpha=0.3)

    # â”€ Avg Val Accuracy â”€
    axes[2].plot(epochs_x, avg_val_accs, 'g-', linewidth=2, label='Avg Val Acc')
    axes[2].axvline(best_epoch, color='gray', linestyle=':', alpha=0.7, label=f'Best Epoch {best_epoch}')
    axes[2].axhline(best_avg_acc, color='green', linestyle='--', alpha=0.6,
                    label=f'Best Val Acc {best_avg_acc*100:.1f}%')
    axes[2].set_title('Avg Val Accuracy'); axes[2].set_xlabel('Epoch'); axes[2].set_ylabel('Accuracy')
    axes[2].set_ylim(0, 1);                axes[2].legend();             axes[2].grid(True, alpha=0.3)

    plt.suptitle('Anomaly Model Training History', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig('anomaly_training_history.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("  âœ… Saved: anomaly_training_history.png")


# ===============================
# ENTRY POINT
# ===============================

if __name__ == "__main__":
    train()
